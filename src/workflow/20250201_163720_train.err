
The following have been reloaded with a version change:
  1) python3/3.7.0 => python3/3.9.2

[rank: 21] Seed set to 42
[rank: 22] Seed set to 42
[rank: 23] Seed set to 42
[rank: 20] Seed set to 42
Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/24
[rank: 17] Seed set to 42
[rank: 18] Seed set to 42
[rank: 16] Seed set to 42
[rank: 19] Seed set to 42
[rank: 3] Seed set to 42
[rank: 0] Seed set to 42
[rank: 7] Seed set to 42
[rank: 8] Seed set to 42
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
[rank: 6] Seed set to 42
[rank: 4] Seed set to 42
[rank: 5] Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/24
[rank: 10] Seed set to 42
[rank: 11] Seed set to 42
[rank: 9] Seed set to 42
[rank: 13] Seed set to 42
[rank: 12] Seed set to 42
[rank: 14] Seed set to 42
[rank: 15] Seed set to 42
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/24
Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/24
Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/24
Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/24
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/24
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/24
Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/24
Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/24
Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/24
Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/24
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/24
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/24
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/24
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/24
Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/24
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/24
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/24
Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/24
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/24
Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/24
Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/24
Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/24
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 24 processes
----------------------------------------------------------------------------------------------------

/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /work2/10214/yu_yao/frontera/deepfaker/src/ckpt exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name    | Type              | Params | Mode 
------------------------------------------------------
0 | model   | VRES_CNN_64to1024 | 315 M  | train
1 | loss_fn | MSELoss           | 0      | train
------------------------------------------------------
315 M     Trainable params
0         Non-trainable params
315 M     Total params
1,261.912 Total estimated model params size (MB)
52        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Errorterminate called after throwing an instance of ''
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
c10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acccdb03446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acccdaad6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acccda1aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ad77492c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ad7748d66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ad774843a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acccda1ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acc99ad4c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acc99add735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2acc82fde630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acccdae469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acccdadd37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acccdadd529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2acc832a4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2acc832a4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acccdb03446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b934be18446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b934bdc26e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b934bd2fa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acccdaad6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acccda1aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acccda1ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acc99ad4c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acc99add735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2acc82fde630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ad774843d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ad7408fdc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ad740906735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ad729e07630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ad77490d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ad77490637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ad774906529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2acccdae469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8631e0d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8631db76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8631d24a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8ed38c3446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8ed386d6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8ed37daa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ad72a0cda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ad72a0cddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ad77492c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b934bd2fd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9317de9c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9317df2735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b93012f3630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b934bdf969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b934bdf237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b934bdf2529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8ed37dad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8e9f894c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8e9f89d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8e88d9e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8ed38a469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8ed389d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8ed389d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ad7748d66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ad774843a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ad774843d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ad7408fdc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ad740906735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ad729e07630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b93015b9a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b93015b9dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2b8e89064a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8e89064dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2ad77490d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abd4201e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abd41fc86e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abd41f35a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b06bd98b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b06bd9356e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b06bd8a2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac0ba9b6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac0ba9606e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac0ba8cda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abd41f35d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abd0dfefc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abd0dff8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abcf74f9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abd41fff69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abd41ff837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abd41ff8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8631d24d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b85fdddec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b85fdde7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b85e72e8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8631dee69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8631de737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8631de7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b06bd8a2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b068995cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0689965735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b0672e66630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b06bd96c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b06bd96537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b06bd965529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac0ba8cdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac086987c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac086990735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac06fe91630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac0ba99769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac0ba99037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac0ba990529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abcf77bfa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abcf77bfdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abd4201e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b85e75aea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b85e75aedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8631e0d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b067312ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b067312cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b06bd98b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac070157a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac070157dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abd41fc86e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abd41f35a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abd41f35d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abd0dfefc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abd0dff8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abcf74f9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8631db76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8631d24a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8631d24d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b85fdddec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b85fdde7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b85e72e8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b06bd9356e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b06bd8a2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b06bd8a2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b068995cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0689965735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b0672e66630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9c2580c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9c257b66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9c25723a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2abd41fff69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b8631dee69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b06bd96c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9c25723d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9bf17ddc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9bf17e6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9bdace7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9c257ed69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9c257e637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9c257e6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ae5998fd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ae5998a76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ae599814a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2a40b71446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2a40b1b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2a40a88a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acccdadd37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acccdadd529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2acc832a4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2acc832a4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #10: <unknown function> + 0x8c1a78 (0x2b9bdafada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9bdafaddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ae599814d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ae5658cec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ae5658d7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ae54edd8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ae5998de69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ae5998d737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ae5998d7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2a40a88d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2a0cb42c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2a0cb4b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b29f604c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2a40b5269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2a40b4b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2a40b4b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acccdb03446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acccdaad6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acccda1aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acccda1ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acc99ad4c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acc99add735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ad77490637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ad774906529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ad72a0cda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ad72a0cddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #10: <unknown function> + 0x8c1a78 (0x2ae54f09ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ae54f09edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ae5998fd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b29f6312a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b29f6312dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2a40b71446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0x5fb630 (0x2acc82fde630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acccdae469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acccdadd37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acccdadd529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2acc832a4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2acc832a4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ad77492c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ad7748d66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ad774843a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ad774843d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ad7408fdc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ad740906735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ae5998a76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ae599814a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ae599814d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ae5658cec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ae5658d7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ae54edd8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2a40b1b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2a40a88a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2a40a88d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2a0cb42c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2a0cb4b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b29f604c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9a5509c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9a550466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9a54fb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b06bd96537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b06bd965529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b067312ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b067312cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #6: <unknown function> + 0x5fb630 (0x2ad729e07630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ad77490d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ad77490637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ad774906529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ad72a0cda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ad72a0cddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2ae5998de69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b2a40b5269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b886ab09446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b886aab36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b886aa20a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adbd5ace446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adbd5a786e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adbd59e5a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abd41ff837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abd41ff8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abcf77bfa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abcf77bfdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af9971e6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af9971906e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af9970fda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b886aa20d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8836adac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8836ae3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b881ffe4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b886aaea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b886aae337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b886aae3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adbd59e5d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adba1a9fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adba1aa8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adb8afa9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2adbd5aaf69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adbd5aa837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adbd5aa8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abd4201e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abd41fc86e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abd41f35a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abd41f35d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abd0dfefc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abd0dff8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af9970fdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af9631b7c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af9631c0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af94c6c1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af9971c769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af9971c037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af9971c0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b88202aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b88202aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b886ab09446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adb8b26fa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adb8b26fdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adbd5ace446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0x5fb630 (0x2abcf74f9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abd41fff69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abd41ff837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abd41ff8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abcf77bfa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abcf77bfdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #10: <unknown function> + 0x8c1a78 (0x2af94c987a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af94c987dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9a54fb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9a2106dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9a21076735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9a0a577630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9a5507d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9a5507637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9a55076529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b886aab36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b886aa20a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b886aa20d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8836adac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8836ae3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b881ffe4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adbd5a786e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adbd59e5a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adbd59e5d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adba1a9fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adba1aa8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adb8afa9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ae5998d737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ae5998d7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ae54f09ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ae54f09edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8631de737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8631de7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b85e75aea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b85e75aedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #10: <unknown function> + 0x8c1a78 (0x2b9a0a83da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9a0a83ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2b886aaea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2adbd5aaf69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b934be18446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b934bdc26e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b934bd2fa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8631e0d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8631db76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8631d24a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8631d24d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b85fdddec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b85fdde7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab7d5a74446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab7d5a1e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab7d598ba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b886aae337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b886aae3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b88202aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b88202aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9c2580c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9c257b66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9c25723a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b934bd2fd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9317de9c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9317df2735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b93012f3630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b934bdf969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b934bdf237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b934bdf2529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0x5fb630 (0x2b85e72e8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8631dee69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8631de737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8631de7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b85e75aea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b85e75aedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab7d598bd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab7a1a45c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab7a1a4e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab78af4f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab7d5a5569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab7d5a4e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab7d5a4e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8ed38c3446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8ed386d6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8ed37daa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9c25723d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9bf17ddc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9bf17e6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9bdace7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9c257ed69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9c257e637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9c257e6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b93015b9a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b93015b9dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b934be18446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8631e0d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8631db76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8631d24a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab78b215a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab78b215dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab7d5a74446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8ed37dad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8e9f894c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8e9f89d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8e88d9e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8ed38a469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8ed389d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8ed389d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b9bdafada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9bdafaddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9c2580c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b934bdc26e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b934bd2fa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b934bd2fd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9317de9c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9317df2735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b93012f3630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8631d24d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab7d5a1e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab7d598ba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab7d598bd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab7a1a45c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab7a1a4e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab78af4f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8e89064a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8e89064dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9c257b66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9c25723a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9c25723d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9bf17ddc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9bf17e6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9bdace7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b934bdf969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4058343446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b40582ed6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b405825aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2a40b4b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2a40b4b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b29f6312a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b29f6312dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2ab7d5a5569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b886ab09446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b886aab36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b886aa20a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b9c257ed69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b934bdf237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b934bdf2529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b93015b9a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b93015b9dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1a8b2d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1a8b2836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1a8b1f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b7aa701d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b7aa6fc76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b7aa6f34a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b886aa20d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8836adac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8836ae3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b881ffe4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b886aaea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b886aae337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b886aae3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adbd5aa837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adbd5aa8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adb8b26fa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adb8b26fdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b934be18446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b934bdc26e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b934bd2fa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b405825ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b4024314c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b402431d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b400d81e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b405832469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b405831d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b405831d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1a8b1f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1a572aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1a572b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1a407b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1a8b2ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1a8b2b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1a8b2b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b7aa6f34d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b7a72feec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b7a72ff7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b7a5c4f8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b7aa6ffe69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b7aa6ff737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b7aa6ff7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b88202aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b88202aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9c257e637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9c257e6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b9bdafada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9bdafaddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b934bd2fd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9317de9c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9317df2735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b93012f3630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b934bdf969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b934bdf237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b934bdf2529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b400dae4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b400dae4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2b1a40a7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1a40a7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1a8b2d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b7a5c7bea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b7a5c7bedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b7aa701d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)

frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9c2580c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9c257b66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9c25723a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9c25723d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9bf17ddc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9bf17e6735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b93015b9a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b93015b9dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b21bf1a4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b21bf14e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b21bf0bba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1a8b2836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1a8b1f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1a8b1f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1a572aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1a572b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1a407b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b7aa6fc76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b7aa6f34a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b7aa6f34d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b7a72feec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b7a72ff7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b7a5c4f8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b06bd98b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b06bd9356e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b06bd8a2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9bdace7630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9c257ed69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9c257e637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9c257e6529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b9bdafada78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9bdafaddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b21bf0bbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b218b175c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b218b17e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b217467f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b21bf18569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b21bf17e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b21bf17e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b1a8b2ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b7aa6ffe69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b06bd8a2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b068995cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0689965735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b0672e66630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b06bd96c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b06bd96537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b06bd965529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adbd5ace446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adbd5a786e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adbd59e5a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b11c5400446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b11c53aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b11c5317a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2174945a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2174945dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #4: <unknown function> + 0x1021c4a (0x2b85fdddec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b85fdde7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b85e72e8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8631dee69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8631de737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8631de7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b85e75aea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9a5509c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9a550466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9a54fb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b067312ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b067312cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adbd59e5d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adba1a9fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adba1aa8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adb8afa9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2adbd5aaf69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adbd5aa837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adbd5aa8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b11c5317d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b11913d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b11913da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b117a8db630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b11c53e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b11c53da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b11c53da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2e7a8e4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2e7a88e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2e7a7fba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b85e75aedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9a54fb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9a2106dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9a21076735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9a0a577630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9a5507d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9a5507637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9a55076529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b06bd98b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b06bd9356e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b06bd8a2a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adb8b26fa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adb8b26fdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adbd5ace446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b117aba1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b117aba1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2e7a7fbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2e468b5c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2e468be735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2e2fdbf630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2e7a8c569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2e7a8be37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2e7a8be529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1a8b2b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1a8b2b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1a40a7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1a40a7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #10: <unknown function> + 0x8c1a78 (0x2b9a0a83da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9a0a83ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9a5509c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b06bd8a2d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b068995cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0689965735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b0672e66630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b06bd96c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b06bd96537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b06bd965529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adbd5a786e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adbd59e5a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adbd59e5d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adba1a9fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adba1aa8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adb8afa9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b11c5400446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b11c53aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b11c5317a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2e30085a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2e30085dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2e7a8e4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1a8b2d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1a8b2836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1a8b1f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1a8b1f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1a572aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1a572b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9a550466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9a54fb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9a54fb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9a2106dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9a21076735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9a0a577630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b067312ca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b067312cdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2adbd5aaf69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b11c5317d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b11913d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b11913da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b117a8db630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b11c53e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b11c53da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b11c53da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2e7a88e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2e7a7fba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2e7a7fbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2e468b5c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2e468be735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2e2fdbf630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1a407b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1a8b2ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1a8b2b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1a8b2b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1a40a7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1a40a7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
frame #7: <unknown function> + 0x6f69f (0x2b9a5507d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8ed38c3446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8ed386d6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8ed37daa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac0ba9b6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac0ba9606e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac0ba8cda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b117aba1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b117aba1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b11c5400446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b2e7a8c569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1a8b2d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1a8b2836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1a8b1f0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2bcc096446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2bcc0406e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2bcbfada18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8ed37dad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8e9f894c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8e9f89d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8e88d9e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8ed38a469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8ed389d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8ed389d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac0ba8cdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac086987c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac086990735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac06fe91630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac0ba99769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac0ba99037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac0ba990529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b11c53aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b11c5317a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b11c5317d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b11913d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b11913da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b117a8db630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2e7a8be37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2e7a8be529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2e30085a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2e30085dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1a8b1f0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2bcbfadd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2b98067c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2b98070735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2b81571630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2bcc07769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2bcc07037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2bcc070529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8e89064a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8e89064dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2ac070157a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac070157dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2b11c53e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2e7a8e4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2e7a88e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2e7a7fba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2e7a7fbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2e468b5c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2e468be735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1a572aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1a572b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1a407b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1a8b2ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1a8b2b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1a8b2b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1a40a7aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2b81837a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2b81837dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2bcc096446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b886ab09446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b886aab36e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b886aa20a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adbd5aa837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adbd5aa8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adb8b26fa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adb8b26fdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b11c53da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b11c53da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b117aba1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b117aba1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b2e2fdbf630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2e7a8c569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2e7a8be37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2e7a8be529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2e30085a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2e30085dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1a40a7adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2bcc0406e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2bcbfada18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2bcbfadd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2b98067c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2b98070735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2b81571630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b886aa20d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8836adac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8836ae3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b881ffe4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b886aaea69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b886aae337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b886aae3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac0ba9b6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac0ba9606e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac0ba8cda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b11c5400446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b11c53aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b11c5317a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b11c5317d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b11913d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b11913da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2e7a8e4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2e7a88e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2e7a7fba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af9971e6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af9971906e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af9970fda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b2bcc07769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b88202aaa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b88202aadc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac0ba8cdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac086987c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac086990735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac06fe91630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac0ba99769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac0ba99037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac0ba990529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0x5fb630 (0x2b117a8db630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b11c53e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b11c53da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b11c53da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b117aba1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b117aba1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2e7a7fbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af9970fdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af9631b7c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af9631c0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af94c6c1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af9971c769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af9971c037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af9971c0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab7d5a4e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab7d5a4e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab78b215a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab78b215dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8ed38c3446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8ed386d6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8ed37daa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac070157a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac070157dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ae5998fd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ae5998a76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ae599814a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2e468b5c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2e468be735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2e2fdbf630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2e7a8c569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2e7a8be37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2e7a8be529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2e30085a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af94c987a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af94c987dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab7d5a74446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab7d5a1e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab7d598ba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab7d598bd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab7a1a45c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab7a1a4e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8ed37dad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8e9f894c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8e9f89d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8e88d9e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8ed38a469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8ed389d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8ed389d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ae599814d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ae5658cec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ae5658d7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ae54edd8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ae5998de69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ae5998d737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ae5998d7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2e30085dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af9971e6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af9971906e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af9970fda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab78af4f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab7d5a5569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab7d5a4e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab7d5a4e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab78b215a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab78b215dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



frame #10: <unknown function> + 0x8c1a78 (0x2b8e89064a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8e89064dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ad77492c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ad7748d66e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ad774843a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ae54f09ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ae54f09edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4058343446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b40582ed6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b405825aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af9970fdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af9631b7c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af9631c0735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af94c6c1630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af9971c769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af9971c037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af9971c0529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b7aa6ff737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b7aa6ff7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b7a5c7bea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b7a5c7bedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acccdb03446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acccdaad6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acccda1aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ad774843d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ad7408fdc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ad740906735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ad729e07630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ad77490d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ad77490637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ad774906529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b405825ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b4024314c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b402431d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b400d81e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b405832469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b405831d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b405831d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af94c987a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af94c987dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9a5507637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9a55076529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b9a0a83da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9a0a83ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acccda1ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acc99ad4c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acc99add735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2acc82fde630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acccdae469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acccdadd37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acccdadd529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ad72a0cda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ad72a0cddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abd4201e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abd41fc86e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abd41f35a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b400dae4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b400dae4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2bcc07037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2bcc070529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2b81837a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2b81837dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2acc832a4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2acc832a4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac0ba9b6446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac0ba9606e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac0ba8cda18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abd41f35d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abd0dfefc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abd0dff8735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abcf74f9630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abd41fff69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abd41ff837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abd41ff8529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4058343446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b40582ed6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b405825aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2a40b71446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2a40b1b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2a40a88a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2bcc096446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2bcc0406e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2bcbfada18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac0ba8cdd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac086987c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac086990735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac06fe91630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac0ba99769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac0ba99037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac0ba990529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abcf77bfa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abcf77bfdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b405825ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b4024314c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b402431d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b400d81e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b405832469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b405831d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b405831d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2a40a88d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2a0cb42c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2a0cb4b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b29f604c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2a40b5269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2a40b4b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2a40b4b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2bcbfadd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2b98067c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2b98070735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2b81571630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2bcc07769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2bcc07037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2bcc070529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac070157a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac070157dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ae5998fd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ae5998a76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ae599814a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b400dae4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b400dae4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2b29f6312a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b29f6312dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2b2b81837a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2b81837dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ae599814d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ae5658cec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ae5658d7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ae54edd8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ae5998de69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ae5998d737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ae5998d7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b594c061446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b594c00b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b594bf78a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2a40b71446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2a40b1b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2a40a88a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b2bcc096446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b2bcc0406e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b2bcbfada18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ae54f09ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ae54f09edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b594bf78d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5918032c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b591803b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b590153c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b594c04269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b594c03b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b594c03b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2a40a88d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2a0cb42c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2a0cb4b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b29f604c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2a40b5269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2a40b4b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2a40b4b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b2bcbfadd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b2b98067c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b2b98070735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2b81571630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b2bcc07769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b2bcc07037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b2bcc070529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5901802a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5901802dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #10: <unknown function> + 0x8c1a78 (0x2b29f6312a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b29f6312dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #10: <unknown function> + 0x8c1a78 (0x2b2b81837a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2b81837dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b594c061446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b594c00b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b594bf78a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab7d5a74446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab7d5a1e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab7d598ba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b594bf78d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5918032c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b591803b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b590153c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b594c04269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b594c03b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b594c03b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab7d598bd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab7a1a45c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab7a1a4e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab78af4f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab7d5a5569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab7d5a4e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab7d5a4e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5901802a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5901802dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #10: <unknown function> + 0x8c1a78 (0x2ab78b215a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab78b215dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b594c061446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b594c00b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b594bf78a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b7aa701d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b7aa6fc76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b7aa6f34a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b594bf78d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5918032c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b591803b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b590153c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b594c04269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b594c03b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b594c03b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b7aa6f34d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b7a72feec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b7a72ff7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b7a5c4f8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b7aa6ffe69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b7aa6ff737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b7aa6ff7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5901802a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5901802dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b594c061446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b7a5c7bea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b7a5c7bedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b594c00b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b594bf78a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b594bf78d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5918032c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b591803b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b590153c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9a5509c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9a550466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9a54fb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b594c04269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9a54fb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b9a2106dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b9a21076735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9a0a577630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9a5507d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9a5507637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9a55076529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b21bf1a4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b21bf14e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b21bf0bba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b9a0a83da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b9a0a83ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b21bf0bbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b218b175c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b218b17e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b217467f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b21bf18569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b21bf17e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b21bf17e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b7aa701d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b7aa6fc76e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b7aa6f34a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2174945a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2174945dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b21bf1a4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b7aa6f34d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b7a72feec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b7a72ff7735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b7a5c4f8630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b7aa6ffe69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b7aa6ff737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b7aa6ff7529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b21bf14e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b21bf0bba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b21bf0bbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b218b175c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b218b17e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b217467f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b7a5c7bea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b7a5c7bedc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #7: <unknown function> + 0x6f69f (0x2b21bf18569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b594c03b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b594c03b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5901802a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5901802dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b21bf17e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b21bf17e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2174945a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2174945dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b21bf1a4446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b21bf14e6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b21bf0bba18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b21bf0bbd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b218b175c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b218b17e735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b217467f630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b21bf18569f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b21bf17e37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b21bf17e529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2174945a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2174945dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4058343446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b40582ed6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b405825aa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b405825ad02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b4024314c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b402431d735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b400d81e630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b405832469f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b405831d37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b405831d529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b400dae4a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b400dae4dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

[rank13]: Traceback (most recent call last):
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank13]:     data = self._data_queue.get(timeout=timeout)
[rank13]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank13]:     self.not_empty.wait(remaining)
[rank13]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank13]:     gotit = waiter.acquire(True, timeout)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank13]:     _error_if_any_worker_fails()
[rank13]: RuntimeError: DataLoader worker (pid 27255) is killed by signal: Aborted. 

[rank13]: The above exception was the direct cause of the following exception:

[rank13]: Traceback (most recent call last):
[rank13]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank13]:     main(
[rank13]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank13]:     trainer.fit(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank13]:     call._call_and_handle_interrupt(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank13]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank13]:     return function(*args, **kwargs)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank13]:     self._run(model, ckpt_path=ckpt_path)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank13]:     results = self._run_stage()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank13]:     self.fit_loop.run()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank13]:     self.advance()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank13]:     self.epoch_loop.run(self._data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank13]:     self.advance(data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank13]:     batch, _, __ = next(data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank13]:     batch = super().__next__()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank13]:     batch = next(self.iterator)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank13]:     out = next(self._iterator)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank13]:     out[i] = next(self.iterators[i])
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank13]:     data = self._next_data()
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank5]:     data = self._data_queue.get(timeout=timeout)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank5]:     self.not_empty.wait(remaining)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank5]:     gotit = waiter.acquire(True, timeout)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank5]:     _error_if_any_worker_fails()
[rank5]: RuntimeError: DataLoader worker (pid 28480) is killed by signal: Aborted. 

[rank5]: The above exception was the direct cause of the following exception:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank5]:     main(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank13]:     idx, data = self._get_data()
[rank22]: Traceback (most recent call last):
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank22]:     data = self._data_queue.get(timeout=timeout)
[rank22]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank22]:     self.not_empty.wait(remaining)
[rank22]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank22]:     gotit = waiter.acquire(True, timeout)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank22]:     _error_if_any_worker_fails()
[rank22]: RuntimeError: DataLoader worker (pid 21306) is killed by signal: Aborted. 

[rank22]: The above exception was the direct cause of the following exception:

[rank22]: Traceback (most recent call last):
[rank22]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank5]:     trainer.fit(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank5]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank12]:     data = self._data_queue.get(timeout=timeout)
[rank12]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank12]:     self.not_empty.wait(remaining)
[rank12]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank12]:     gotit = waiter.acquire(True, timeout)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank12]:     _error_if_any_worker_fails()
[rank12]: RuntimeError: DataLoader worker (pid 27258) is killed by signal: Aborted. 

[rank12]: The above exception was the direct cause of the following exception:

[rank12]: Traceback (most recent call last):
[rank12]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank22]:     main(
[rank22]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank22]:     trainer.fit(
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank22]:     call._call_and_handle_interrupt(
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank22]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank22]:     return function(*args, **kwargs)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank22]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank5]:     results = self._run_stage()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank5]:     self.advance()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank12]:     main(
[rank12]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank12]:     trainer.fit(
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank12]:     call._call_and_handle_interrupt(
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank12]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank12]:     return function(*args, **kwargs)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank12]:     self._run(model, ckpt_path=ckpt_path)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank22]:     results = self._run_stage()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank22]:     self.fit_loop.run()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank22]:     self.advance()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank22]:     self.epoch_loop.run(self._data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank22]:     self.advance(data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank5]:     batch, _, __ = next(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank5]:     batch = super().__next__()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank5]:     batch = next(self.iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank5]:     out = next(self._iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank5]:     out[i] = next(self.iterators[i])
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank5]:     data = self._next_data()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank12]:     results = self._run_stage()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank12]:     self.fit_loop.run()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank12]:     self.advance()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank12]:     self.epoch_loop.run(self._data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank12]:     self.advance(data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank22]:     batch, _, __ = next(data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank22]:     batch = super().__next__()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank22]:     batch = next(self.iterator)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank22]:     out = next(self._iterator)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank22]:     out[i] = next(self.iterators[i])
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank22]:     data = self._next_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank5]:     idx, data = self._get_data()
[rank12]:     batch, _, __ = next(data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank12]:     batch = super().__next__()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank12]:     batch = next(self.iterator)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank12]:     out = next(self._iterator)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank12]:     out[i] = next(self.iterators[i])
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank12]:     data = self._next_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank22]:     idx, data = self._get_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank5]:     success, data = self._try_get_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank5]:     raise RuntimeError(
[rank5]: RuntimeError: DataLoader worker (pid(s) 28473, 28477, 28480, 28484) exited unexpectedly
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank12]:     idx, data = self._get_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank22]:     success, data = self._try_get_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank22]:     raise RuntimeError(
[rank22]: RuntimeError: DataLoader worker (pid(s) 21293, 21298, 21302, 21306) exited unexpectedly
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank4]:     data = self._data_queue.get(timeout=timeout)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank4]:     self.not_empty.wait(remaining)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank4]:     gotit = waiter.acquire(True, timeout)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank4]:     _error_if_any_worker_fails()
[rank4]: RuntimeError: DataLoader worker (pid 28485) is killed by signal: Aborted. 

[rank4]: The above exception was the direct cause of the following exception:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank4]:     main(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank13]:     success, data = self._try_get_data()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank13]:     raise RuntimeError(
[rank13]: RuntimeError: DataLoader worker (pid(s) 27247, 27251, 27255, 27259) exited unexpectedly
[rank20]: Traceback (most recent call last):
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank20]:     data = self._data_queue.get(timeout=timeout)
[rank20]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank20]:     self.not_empty.wait(remaining)
[rank20]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank20]:     gotit = waiter.acquire(True, timeout)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank20]:     _error_if_any_worker_fails()
[rank20]: RuntimeError: DataLoader worker (pid 21300) is killed by signal: Aborted. 

[rank20]: The above exception was the direct cause of the following exception:

[rank20]: Traceback (most recent call last):
[rank20]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank4]:     trainer.fit(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank4]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank12]:     success, data = self._try_get_data()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank12]:     raise RuntimeError(
[rank12]: RuntimeError: DataLoader worker (pid(s) 27246, 27250, 27254, 27258) exited unexpectedly
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank4]:     results = self._run_stage()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank4]:     self.fit_loop.run()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank4]:     self.advance()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank15]: Traceback (most recent call last):
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank15]:     data = self._data_queue.get(timeout=timeout)
[rank15]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank15]:     self.not_empty.wait(remaining)
[rank15]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank15]:     gotit = waiter.acquire(True, timeout)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank15]:     _error_if_any_worker_fails()
[rank15]: RuntimeError: DataLoader worker (pid 27265) is killed by signal: Aborted. 

[rank15]: The above exception was the direct cause of the following exception:

[rank15]: Traceback (most recent call last):
[rank15]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank4]:     batch, _, __ = next(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank4]:     batch = super().__next__()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank4]:     batch = next(self.iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank4]:     out = next(self._iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank4]:     out[i] = next(self.iterators[i])
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank4]:     data = self._next_data()
[rank15]:     main(
[rank15]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank15]:     trainer.fit(
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank15]:     call._call_and_handle_interrupt(
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank15]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank15]:     return function(*args, **kwargs)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank15]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank4]:     idx, data = self._get_data()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank15]:     results = self._run_stage()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank15]:     self.fit_loop.run()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank15]:     self.advance()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank15]:     self.epoch_loop.run(self._data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank15]:     self.advance(data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank4]:     success, data = self._try_get_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank4]:     raise RuntimeError(
[rank4]: RuntimeError: DataLoader worker (pid(s) 28472, 28476, 28481, 28485) exited unexpectedly
[rank15]:     batch, _, __ = next(data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank15]:     batch = super().__next__()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank15]:     batch = next(self.iterator)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank15]:     out = next(self._iterator)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank15]:     out[i] = next(self.iterators[i])
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank15]:     data = self._next_data()
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank6]:     data = self._data_queue.get(timeout=timeout)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank6]:     self.not_empty.wait(remaining)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank6]:     gotit = waiter.acquire(True, timeout)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank6]:     _error_if_any_worker_fails()
[rank6]: RuntimeError: DataLoader worker (pid 28488) is killed by signal: Aborted. 

[rank6]: The above exception was the direct cause of the following exception:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank6]:     main(
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank15]:     idx, data = self._get_data()
[rank20]:     main(
[rank20]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank20]:     trainer.fit(
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank20]:     call._call_and_handle_interrupt(
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank20]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank20]:     return function(*args, **kwargs)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank20]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank6]:     trainer.fit(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank6]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank15]:     success, data = self._try_get_data()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank15]:     raise RuntimeError(
[rank15]: RuntimeError: DataLoader worker (pid(s) 27248, 27252, 27256, 27265) exited unexpectedly
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank20]:     results = self._run_stage()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank20]:     self.fit_loop.run()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank20]:     self.advance()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank20]:     self.epoch_loop.run(self._data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank20]:     self.advance(data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank6]:     results = self._run_stage()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank6]:     self.fit_loop.run()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank6]:     self.advance()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank14]: Traceback (most recent call last):
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank14]:     data = self._data_queue.get(timeout=timeout)
[rank14]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank14]:     self.not_empty.wait(remaining)
[rank14]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank14]:     gotit = waiter.acquire(True, timeout)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank14]:     _error_if_any_worker_fails()
[rank14]: RuntimeError: DataLoader worker (pid 27249) is killed by signal: Aborted. 

[rank14]: The above exception was the direct cause of the following exception:

[rank14]: Traceback (most recent call last):
[rank14]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank20]:     batch, _, __ = next(data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank20]:     batch = super().__next__()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank20]:     batch = next(self.iterator)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank20]:     out = next(self._iterator)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank20]:     out[i] = next(self.iterators[i])
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank20]:     data = self._next_data()
[rank6]:     batch, _, __ = next(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank6]:     batch = super().__next__()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank6]:     batch = next(self.iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank6]:     out = next(self._iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank6]:     out[i] = next(self.iterators[i])
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank6]:     data = self._next_data()
[rank14]:     main(
[rank14]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank14]:     trainer.fit(
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank14]:     call._call_and_handle_interrupt(
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank14]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank14]:     return function(*args, **kwargs)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank14]:     self._run(model, ckpt_path=ckpt_path)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank20]:     idx, data = self._get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank6]:     idx, data = self._get_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank14]:     results = self._run_stage()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank14]:     self.fit_loop.run()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank14]:     self.advance()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank14]:     self.epoch_loop.run(self._data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank14]:     self.advance(data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank20]:     success, data = self._try_get_data()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank20]:     raise RuntimeError(
[rank20]: RuntimeError: DataLoader worker (pid(s) 21296, 21300, 21304, 21317) exited unexpectedly
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank6]:     success, data = self._try_get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank6]:     raise RuntimeError(
[rank6]: RuntimeError: DataLoader worker (pid(s) 28474, 28478, 28483, 28488) exited unexpectedly
[rank14]:     batch, _, __ = next(data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank14]:     batch = super().__next__()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank14]:     batch = next(self.iterator)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank14]:     out = next(self._iterator)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank14]:     out[i] = next(self.iterators[i])
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank14]:     data = self._next_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank14]:     idx, data = self._get_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank14]:     success, data = self._try_get_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank14]:     raise RuntimeError(
[rank14]: RuntimeError: DataLoader worker (pid(s) 27249, 27253, 27257, 27273) exited unexpectedly
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank1]:     data = self._data_queue.get(timeout=timeout)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank1]:     self.not_empty.wait(remaining)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank1]:     gotit = waiter.acquire(True, timeout)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank1]:     _error_if_any_worker_fails()
[rank1]: RuntimeError: DataLoader worker (pid 15146) is killed by signal: Aborted. 

[rank1]: The above exception was the direct cause of the following exception:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank1]:     main(
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank1]:     trainer.fit(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank1]:     self.advance()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank1]:     batch, _, __ = next(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank1]:     batch = super().__next__()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank1]:     batch = next(self.iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank1]:     out = next(self._iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank1]:     out[i] = next(self.iterators[i])
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank1]:     data = self._next_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank1]:     idx, data = self._get_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank1]:     success, data = self._try_get_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank1]:     raise RuntimeError(
[rank1]: RuntimeError: DataLoader worker (pid(s) 15134, 15137, 15141, 15146) exited unexpectedly
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank7]:     data = self._data_queue.get(timeout=timeout)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank7]:     self.not_empty.wait(remaining)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank7]:     gotit = waiter.acquire(True, timeout)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank7]:     _error_if_any_worker_fails()
[rank7]: RuntimeError: DataLoader worker (pid 28487) is killed by signal: Aborted. 

[rank7]: The above exception was the direct cause of the following exception:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank7]:     main(
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank7]:     trainer.fit(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank7]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank7]:     results = self._run_stage()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank7]:     self.fit_loop.run()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank7]:     self.advance()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank7]:     batch, _, __ = next(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank7]:     batch = super().__next__()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank7]:     batch = next(self.iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank7]:     out = next(self._iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank7]:     out[i] = next(self.iterators[i])
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank7]:     data = self._next_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank7]:     idx, data = self._get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank7]:     success, data = self._try_get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank7]:     raise RuntimeError(
[rank7]: RuntimeError: DataLoader worker (pid(s) 28475, 28479, 28482, 28487) exited unexpectedly
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank0]:     self.not_empty.wait(remaining)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank0]:     gotit = waiter.acquire(True, timeout)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank0]:     _error_if_any_worker_fails()
[rank0]: RuntimeError: DataLoader worker (pid 15139) is killed by signal: Aborted. 

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank0]:     main(
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank0]:     trainer.fit(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank0]:     self.advance()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank0]:     batch, _, __ = next(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank0]:     batch = super().__next__()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank0]:     batch = next(self.iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank0]:     out = next(self._iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank0]:     out[i] = next(self.iterators[i])
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank0]:     raise RuntimeError(
[rank0]: RuntimeError: DataLoader worker (pid(s) 15133, 15139, 15143) exited unexpectedly
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank3]:     data = self._data_queue.get(timeout=timeout)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank3]:     self.not_empty.wait(remaining)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank3]:     gotit = waiter.acquire(True, timeout)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank3]:     _error_if_any_worker_fails()
[rank3]: RuntimeError: DataLoader worker (pid 15160) is killed by signal: Aborted. 

[rank3]: The above exception was the direct cause of the following exception:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank3]:     main(
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank3]:     trainer.fit(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank3]:     self.advance()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank3]:     batch, _, __ = next(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank3]:     batch = super().__next__()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank3]:     batch = next(self.iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank3]:     out = next(self._iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank3]:     out[i] = next(self.iterators[i])
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank3]:     data = self._next_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank3]:     idx, data = self._get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank3]:     success, data = self._try_get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank3]:     raise RuntimeError(
[rank3]: RuntimeError: DataLoader worker (pid(s) 15136, 15140, 15144, 15160) exited unexpectedly
[rank21]: Traceback (most recent call last):
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank21]:     data = self._data_queue.get(timeout=timeout)
[rank21]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank21]:     self.not_empty.wait(remaining)
[rank21]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank21]:     gotit = waiter.acquire(True, timeout)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank21]:     _error_if_any_worker_fails()
[rank21]: RuntimeError: DataLoader worker (pid 21297) is killed by signal: Aborted. 

[rank21]: The above exception was the direct cause of the following exception:

[rank21]: Traceback (most recent call last):
[rank21]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank21]:     main(
[rank21]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank21]:     trainer.fit(
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank21]:     call._call_and_handle_interrupt(
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank21]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank21]:     return function(*args, **kwargs)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank21]:     self._run(model, ckpt_path=ckpt_path)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank21]:     results = self._run_stage()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank21]:     self.fit_loop.run()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank21]:     self.advance()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank21]:     self.epoch_loop.run(self._data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank21]:     self.advance(data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank21]:     batch, _, __ = next(data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank21]:     batch = super().__next__()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank21]:     batch = next(self.iterator)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank21]:     out = next(self._iterator)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank21]:     out[i] = next(self.iterators[i])
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank21]:     data = self._next_data()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank21]:     idx, data = self._get_data()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank21]:     success, data = self._try_get_data()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank21]:     raise RuntimeError(
[rank21]: RuntimeError: DataLoader worker (pid(s) 21294, 21297, 21301, 21305) exited unexpectedly
[rank23]: Traceback (most recent call last):
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank23]:     data = self._data_queue.get(timeout=timeout)
[rank23]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank23]:     self.not_empty.wait(remaining)
[rank23]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank23]:     gotit = waiter.acquire(True, timeout)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank23]:     _error_if_any_worker_fails()
[rank23]: RuntimeError: DataLoader worker (pid 21303) is killed by signal: Aborted. 

[rank23]: The above exception was the direct cause of the following exception:

[rank23]: Traceback (most recent call last):
[rank23]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank23]:     main(
[rank23]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank23]:     trainer.fit(
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank23]:     call._call_and_handle_interrupt(
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank23]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank23]:     return function(*args, **kwargs)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank23]:     self._run(model, ckpt_path=ckpt_path)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank23]:     results = self._run_stage()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank23]:     self.fit_loop.run()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank23]:     self.advance()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank23]:     self.epoch_loop.run(self._data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank23]:     self.advance(data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank23]:     batch, _, __ = next(data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank23]:     batch = super().__next__()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank23]:     batch = next(self.iterator)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank23]:     out = next(self._iterator)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank23]:     out[i] = next(self.iterators[i])
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank23]:     data = self._next_data()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank23]:     idx, data = self._get_data()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank23]:     success, data = self._try_get_data()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank23]:     raise RuntimeError(
[rank23]: RuntimeError: DataLoader worker (pid(s) 21295, 21299, 21303, 21311) exited unexpectedly
[rank19]: Traceback (most recent call last):
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank19]:     data = self._data_queue.get(timeout=timeout)
[rank19]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank19]:     self.not_empty.wait(remaining)
[rank19]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank19]:     gotit = waiter.acquire(True, timeout)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank19]:     _error_if_any_worker_fails()
[rank19]: RuntimeError: DataLoader worker (pid 29739) is killed by signal: Aborted. 

[rank19]: The above exception was the direct cause of the following exception:

[rank19]: Traceback (most recent call last):
[rank19]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank19]:     main(
[rank19]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank19]:     trainer.fit(
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank19]:     call._call_and_handle_interrupt(
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank19]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank19]:     return function(*args, **kwargs)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank19]:     self._run(model, ckpt_path=ckpt_path)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank19]:     results = self._run_stage()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank19]:     self.fit_loop.run()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank19]:     self.advance()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank19]:     self.epoch_loop.run(self._data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank19]:     self.advance(data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank19]:     batch, _, __ = next(data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank19]:     batch = super().__next__()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank19]:     batch = next(self.iterator)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank19]:     out = next(self._iterator)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank19]:     out[i] = next(self.iterators[i])
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank19]:     data = self._next_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank19]:     idx, data = self._get_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank19]:     success, data = self._try_get_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank19]:     raise RuntimeError(
[rank19]: RuntimeError: DataLoader worker (pid(s) 29734, 29739, 29743, 29753) exited unexpectedly
[rank8]: Traceback (most recent call last):
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank8]:     data = self._data_queue.get(timeout=timeout)
[rank8]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank8]:     self.not_empty.wait(remaining)
[rank8]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank8]:     gotit = waiter.acquire(True, timeout)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank8]:     _error_if_any_worker_fails()
[rank8]: RuntimeError: DataLoader worker (pid 13389) is killed by signal: Aborted. 

[rank8]: The above exception was the direct cause of the following exception:

[rank8]: Traceback (most recent call last):
[rank8]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank8]:     main(
[rank8]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank8]:     trainer.fit(
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank8]:     call._call_and_handle_interrupt(
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank8]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank8]:     return function(*args, **kwargs)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank8]:     self._run(model, ckpt_path=ckpt_path)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank8]:     results = self._run_stage()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank8]:     self.fit_loop.run()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank8]:     self.advance()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank8]:     self.epoch_loop.run(self._data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank8]:     self.advance(data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank8]:     batch, _, __ = next(data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank8]:     batch = super().__next__()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank8]:     batch = next(self.iterator)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank8]:     out = next(self._iterator)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank8]:     out[i] = next(self.iterators[i])
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank8]:     data = self._next_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank8]:     idx, data = self._get_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank8]:     success, data = self._try_get_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank8]:     raise RuntimeError(
[rank8]: RuntimeError: DataLoader worker (pid(s) 13385, 13389, 13393, 13405) exited unexpectedly
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank2]:     data = self._data_queue.get(timeout=timeout)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank2]:     self.not_empty.wait(remaining)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank2]:     gotit = waiter.acquire(True, timeout)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank2]:     _error_if_any_worker_fails()
[rank2]: RuntimeError: DataLoader worker (pid 15145) is killed by signal: Aborted. 

[rank2]: The above exception was the direct cause of the following exception:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank2]:     main(
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank2]:     trainer.fit(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank2]:     self.advance()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank2]:     batch, _, __ = next(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank2]:     batch = super().__next__()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank2]:     batch = next(self.iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank2]:     out = next(self._iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank2]:     out[i] = next(self.iterators[i])
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank2]:     data = self._next_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank2]:     idx, data = self._get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank2]:     success, data = self._try_get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank2]:     raise RuntimeError(
[rank2]: RuntimeError: DataLoader worker (pid(s) 15135, 15138, 15142, 15145) exited unexpectedly
[rank16]: Traceback (most recent call last):
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank16]:     data = self._data_queue.get(timeout=timeout)
[rank16]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank16]:     self.not_empty.wait(remaining)
[rank16]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank16]:     gotit = waiter.acquire(True, timeout)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank16]:     _error_if_any_worker_fails()
[rank16]: RuntimeError: DataLoader worker (pid 29744) is killed by signal: Aborted. 

[rank16]: The above exception was the direct cause of the following exception:

[rank16]: Traceback (most recent call last):
[rank16]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank16]:     main(
[rank16]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank16]:     trainer.fit(
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank16]:     call._call_and_handle_interrupt(
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank16]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank16]:     return function(*args, **kwargs)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank16]:     self._run(model, ckpt_path=ckpt_path)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank16]:     results = self._run_stage()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank16]:     self.fit_loop.run()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank16]:     self.advance()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank16]:     self.epoch_loop.run(self._data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank16]:     self.advance(data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank16]:     batch, _, __ = next(data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank16]:     batch = super().__next__()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank16]:     batch = next(self.iterator)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank16]:     out = next(self._iterator)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank16]:     out[i] = next(self.iterators[i])
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank16]:     data = self._next_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank16]:     idx, data = self._get_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank16]:     success, data = self._try_get_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank16]:     raise RuntimeError(
[rank16]: RuntimeError: DataLoader worker (pid(s) 29732, 29736, 29740, 29744) exited unexpectedly
[rank17]: Traceback (most recent call last):
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank17]:     data = self._data_queue.get(timeout=timeout)
[rank17]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank17]:     self.not_empty.wait(remaining)
[rank17]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank17]:     gotit = waiter.acquire(True, timeout)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank17]:     _error_if_any_worker_fails()
[rank17]: RuntimeError: DataLoader worker (pid 29745) is killed by signal: Aborted. 

[rank17]: The above exception was the direct cause of the following exception:

[rank17]: Traceback (most recent call last):
[rank17]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank17]:     main(
[rank17]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank17]:     trainer.fit(
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank17]:     call._call_and_handle_interrupt(
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank17]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank17]:     return function(*args, **kwargs)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank17]:     self._run(model, ckpt_path=ckpt_path)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank17]:     results = self._run_stage()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank17]:     self.fit_loop.run()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank17]:     self.advance()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank17]:     self.epoch_loop.run(self._data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank17]:     self.advance(data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank17]:     batch, _, __ = next(data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank17]:     batch = super().__next__()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank17]:     batch = next(self.iterator)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank17]:     out = next(self._iterator)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank17]:     out[i] = next(self.iterators[i])
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank17]:     data = self._next_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank17]:     idx, data = self._get_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank17]:     success, data = self._try_get_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank17]:     raise RuntimeError(
[rank17]: RuntimeError: DataLoader worker (pid(s) 29733, 29737, 29741, 29745) exited unexpectedly
[rank18]: Traceback (most recent call last):
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank18]:     data = self._data_queue.get(timeout=timeout)
[rank18]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank18]:     self.not_empty.wait(remaining)
[rank18]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank18]:     gotit = waiter.acquire(True, timeout)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank18]:     _error_if_any_worker_fails()
[rank18]: RuntimeError: DataLoader worker (pid 29735) is killed by signal: Aborted. 

[rank18]: The above exception was the direct cause of the following exception:

[rank18]: Traceback (most recent call last):
[rank18]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank18]:     main(
[rank18]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank18]:     trainer.fit(
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank18]:     call._call_and_handle_interrupt(
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank18]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank18]:     return function(*args, **kwargs)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank18]:     self._run(model, ckpt_path=ckpt_path)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank18]:     results = self._run_stage()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank18]:     self.fit_loop.run()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank18]:     self.advance()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank18]:     self.epoch_loop.run(self._data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank18]:     self.advance(data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank18]:     batch, _, __ = next(data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank18]:     batch = super().__next__()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank18]:     batch = next(self.iterator)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank18]:     out = next(self._iterator)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank18]:     out[i] = next(self.iterators[i])
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank18]:     data = self._next_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank18]:     idx, data = self._get_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank18]:     success, data = self._try_get_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank18]:     raise RuntimeError(
[rank18]: RuntimeError: DataLoader worker (pid(s) 29735, 29738, 29742, 29748) exited unexpectedly
[rank9]: Traceback (most recent call last):
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank9]:     data = self._data_queue.get(timeout=timeout)
[rank9]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank9]:     self.not_empty.wait(remaining)
[rank9]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank9]:     gotit = waiter.acquire(True, timeout)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank9]:     _error_if_any_worker_fails()
[rank9]: RuntimeError: DataLoader worker (pid 13395) is killed by signal: Aborted. 

[rank9]: The above exception was the direct cause of the following exception:

[rank9]: Traceback (most recent call last):
[rank9]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank9]:     main(
[rank9]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank9]:     trainer.fit(
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank9]:     call._call_and_handle_interrupt(
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank9]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank9]:     return function(*args, **kwargs)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank9]:     self._run(model, ckpt_path=ckpt_path)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank9]:     results = self._run_stage()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank9]:     self.fit_loop.run()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank9]:     self.advance()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank9]:     self.epoch_loop.run(self._data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank9]:     self.advance(data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank9]:     batch, _, __ = next(data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank9]:     batch = super().__next__()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank9]:     batch = next(self.iterator)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank9]:     out = next(self._iterator)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank9]:     out[i] = next(self.iterators[i])
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank9]:     data = self._next_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank9]:     idx, data = self._get_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank9]:     success, data = self._try_get_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank9]:     raise RuntimeError(
[rank9]: RuntimeError: DataLoader worker (pid(s) 13383, 13387, 13391, 13395) exited unexpectedly
[rank11]: Traceback (most recent call last):
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank11]:     data = self._data_queue.get(timeout=timeout)
[rank11]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank11]:     self.not_empty.wait(remaining)
[rank11]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank11]:     gotit = waiter.acquire(True, timeout)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank11]:     _error_if_any_worker_fails()
[rank11]: RuntimeError: DataLoader worker (pid 13396) is killed by signal: Aborted. 

[rank11]: The above exception was the direct cause of the following exception:

[rank11]: Traceback (most recent call last):
[rank11]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank11]:     main(
[rank11]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank11]:     trainer.fit(
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank11]:     call._call_and_handle_interrupt(
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank11]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank11]:     return function(*args, **kwargs)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank11]:     self._run(model, ckpt_path=ckpt_path)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank11]:     results = self._run_stage()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank11]:     self.fit_loop.run()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank11]:     self.advance()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank11]:     self.epoch_loop.run(self._data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank11]:     self.advance(data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank11]:     batch, _, __ = next(data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank11]:     batch = super().__next__()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank11]:     batch = next(self.iterator)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank11]:     out = next(self._iterator)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank11]:     out[i] = next(self.iterators[i])
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank11]:     data = self._next_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank11]:     idx, data = self._get_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank11]:     success, data = self._try_get_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank11]:     raise RuntimeError(
[rank11]: RuntimeError: DataLoader worker (pid(s) 13384, 13388, 13392, 13396) exited unexpectedly
[rank10]: Traceback (most recent call last):
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank10]:     data = self._data_queue.get(timeout=timeout)
[rank10]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank10]:     self.not_empty.wait(remaining)
[rank10]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank10]:     gotit = waiter.acquire(True, timeout)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank10]:     _error_if_any_worker_fails()
[rank10]: RuntimeError: DataLoader worker (pid 13394) is killed by signal: Aborted. 

[rank10]: The above exception was the direct cause of the following exception:

[rank10]: Traceback (most recent call last):
[rank10]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank10]:     main(
[rank10]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank10]:     trainer.fit(
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank10]:     call._call_and_handle_interrupt(
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank10]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank10]:     return function(*args, **kwargs)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank10]:     self._run(model, ckpt_path=ckpt_path)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank10]:     results = self._run_stage()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank10]:     self.fit_loop.run()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank10]:     self.advance()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank10]:     self.epoch_loop.run(self._data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank10]:     self.advance(data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank10]:     batch, _, __ = next(data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank10]:     batch = super().__next__()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank10]:     batch = next(self.iterator)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank10]:     out = next(self._iterator)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank10]:     out[i] = next(self.iterators[i])
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank10]:     data = self._next_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank10]:     idx, data = self._get_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank10]:     success, data = self._try_get_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank10]:     raise RuntimeError(
[rank10]: RuntimeError: DataLoader worker (pid(s) 13382, 13386, 13390, 13394) exited unexpectedly
srun: error: c199-102: tasks 20-23: Exited with exit code 1
srun: error: c199-071: tasks 12-15: Exited with exit code 1
srun: error: c198-061: tasks 4-7: Exited with exit code 1
srun: error: c199-101: tasks 16-19: Exited with exit code 1
srun: error: c199-031: tasks 8-11: Exited with exit code 1
srun: error: c197-041: tasks 0-3: Exited with exit code 1
