
The following have been reloaded with a version change:
  1) python3/3.7.0 => python3/3.9.2

[rank: 23] Seed set to 42
[rank: 7] Seed set to 42
[rank: 17] Seed set to 42
[rank: 15] Seed set to 42
[rank: 2] Seed set to 42
[rank: 3] Seed set to 42
[rank: 1] Seed set to 42
[rank: 8] Seed set to 42
[rank: 0] Seed set to 42
[rank: 22] Seed set to 42
[rank: 20] Seed set to 42
[rank: 21] Seed set to 42
[rank: 5] Seed set to 42
[rank: 18] Seed set to 42
[rank: 10] Seed set to 42
[rank: 4] Seed set to 42
[rank: 19] Seed set to 42
[rank: 13] Seed set to 42
[rank: 9] Seed set to 42
[rank: 6] Seed set to 42
[rank: 16] Seed set to 42
[rank: 12] Seed set to 42
[rank: 11] Seed set to 42
[rank: 14] Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/24
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/24
Initializing distributed: GLOBAL_RANK: 20, MEMBER: 21/24
Initializing distributed: GLOBAL_RANK: 16, MEMBER: 17/24
Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/24
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/24
Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/24
Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/24
Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/24
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/24
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/24
Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/24
Initializing distributed: GLOBAL_RANK: 17, MEMBER: 18/24
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/24
Initializing distributed: GLOBAL_RANK: 23, MEMBER: 24/24
Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/24
Initializing distributed: GLOBAL_RANK: 18, MEMBER: 19/24
Initializing distributed: GLOBAL_RANK: 19, MEMBER: 20/24
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/24
Initializing distributed: GLOBAL_RANK: 21, MEMBER: 22/24
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/24
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/24
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/24
Initializing distributed: GLOBAL_RANK: 22, MEMBER: 23/24
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 24 processes
----------------------------------------------------------------------------------------------------

/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /work2/10214/yu_yao/frontera/deepfaker/src/ckpt exists and is not empty.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]

  | Name    | Type              | Params | Mode 
------------------------------------------------------
0 | model   | VRES_CNN_64to1024 | 315 M  | train
1 | loss_fn | MSELoss           | 0      | train
------------------------------------------------------
315 M     Trainable params
0         Non-trainable params
315 M     Total params
1,261.912 Total estimated model params size (MB)
52        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Errorterminate called after throwing an instance of ''
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Errorc10::Error'
c10::Error'
'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Errorterminate called after throwing an instance of ''
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Error'
c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'c10::Error'
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
terminate called after throwing an instance of 'c10::Error'
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1e9036d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1e903176e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1e90284a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6224107446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b62240b16e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b622401ea18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abc14600446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abc145aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abc14517a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6d512df446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b6d512896e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b6d511f6a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09779b8446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09779626e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09778cfa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1e90284d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1e5c33ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1e5c347735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1e45848630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1e9034e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1e9034737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1e90347529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b622401ed02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b61f00d8c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b61f00e1735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b61d95e2630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b62240e869f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b62240e137b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b62240e1529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b954511a446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b95450c46e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9545031a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1e45b0ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1e45b0edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #10: <unknown function> + 0x8c1a78 (0x2b61d98a8a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b61d98a8dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6224107446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b5a650d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b5a650836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b5a64ff0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b62240b16e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b622401ea18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b622401ed02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b61f00d8c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b61f00e1735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b61d95e2630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b5a64ff0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5a310aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b5a310b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b5a1a5b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b5a650ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b5a650b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b5a650b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b6d511f6d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b6d1d2b0c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b6d1d2b9735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b6d067ba630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b6d512c069f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b6d512b937b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b6d512b9529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b62240e869f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09778cfd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0943989c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0943992735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b092ce93630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b097799969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b097799237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0977992529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5a1a87aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5a1a87adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b5a650d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b36122d0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b361227a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b36121e7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b5a650836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b5a64ff0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b5a64ff0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5a310aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b5a310b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b5a1a5b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b6d06a80a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b6d06a80dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9545031d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b95110ebc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b95110f4735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b94fa5f5630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b95450fb69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b95450f437b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b95450f4529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b36121e7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b35de2a1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b35de2aa735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b35c77ab630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b36122b169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b36122aa37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b36122aa529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b5a650ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abc14517d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abbe05d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abbe05da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abbc9adb630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abc145e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abc145da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abc145da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af29b4bd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af29b4676e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af29b3d4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b94fa8bba78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b94fa8bbdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b954511a446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b35c7a71a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b35c7a71dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b36122d0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1e9036d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1e903176e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1e90284a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af29b3d4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af26748ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af267497735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af250998630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af29b49e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af29b49737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af29b497529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b95450c46e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9545031a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9545031d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b95110ebc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b95110f4735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b94fa5f5630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b361227a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b36121e7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b36121e7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b35de2a1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b35de2aa735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b35c77ab630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b092d159a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b092d159dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09779b8446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1e90284d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1e5c33ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1e5c347735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1e45848630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1e9034e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1e9034737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1e90347529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af250c5ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af250c5edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af29b4bd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b95450fb69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b36122b169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09779626e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09778cfa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09778cfd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0943989c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0943992735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b092ce93630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1e45b0ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1e45b0edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1e9036d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af29b4676e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af29b3d4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af29b3d4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af26748ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af267497735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af250998630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1b15891446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1b1583b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1b157a8a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b62240e137b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b62240e1529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b61d98a8a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b61d98a8dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #7: <unknown function> + 0x6f69f (0x2b097799969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1e903176e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1e90284a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1e90284d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1e5c33ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1e5c347735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1e45848630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af29b49e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1b157a8d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1ae1862c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1ae186b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1acad6c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1b1587269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1b1586b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1b1586b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6224107446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b62240b16e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b622401ea18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b622401ed02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b61f00d8c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b61f00e1735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4142c9c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b4142c466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b4142bb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b1e9034e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8b23ac9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8b23a736e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8b239e0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1acb032a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1acb032dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1b15891446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #6: <unknown function> + 0x5fb630 (0x2b61d95e2630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b62240e869f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b62240e137b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b62240e1529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b61d98a8a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b61d98a8dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b4142bb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b410ec6dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b410ec76735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b40f8177630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b4142c7d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b4142c7637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b4142c76529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b55d645e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b55d64086e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b55d6375a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abbc9da1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abbc9da1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8b239e0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8aefa9ac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8aefaa3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8ad8fa4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8b23aaa69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8b23aa337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8b23aa3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1b1583b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1b157a8a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1b157a8d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1ae1862c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1ae186b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1acad6c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6224107446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b62240b16e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b622401ea18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b40f843da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b40f843ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4142c9c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b55d6375d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b55a242fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b55a2438735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b558b939630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b55d643f69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b55d643837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b55d6438529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b0539db5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b0539d5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b0539ccca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8ad926aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8ad926adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8b23ac9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b1b1587269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b622401ed02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b4142c466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b4142bb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b4142bb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b410ec6dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b410ec76735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b40f8177630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b558bbffa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b558bbffdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b55d645e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b0539cccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0505d86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0505d8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b04ef290630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b0539d9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b0539d8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0539d8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8b23a736e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8b239e0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8b239e0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8aefa9ac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8aefaa3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8ad8fa4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b063a5ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b063a5566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b063a4c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acefae90446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acefae3a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acefada7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b4142c7d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b55d64086e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b55d6375a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b55d6375d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b55a242fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b55a2438735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b558b939630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b04ef556a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b04ef556dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b0539db5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b8b23aaa69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b063a4c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b060657dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0606586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b05efa87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b063a58d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b063a58637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b063a586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acefada7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acec6e61c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acec6e6a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aceb036b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acefae7169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acefae6a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acefae6a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b097799237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0977992529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b092d159a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b092d159dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #7: <unknown function> + 0x6f69f (0x2b55d643f69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b0539d5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b0539ccca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b0539cccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0505d86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0505d8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b04ef290630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2afc5cfb0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2afc5cf5a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2afc5cec7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b05efd4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b05efd4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b063a5ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aceb0631a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aceb0631dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acefae90446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09779b8446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09779626e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09778cfa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09778cfd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0943989c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0943992735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9980a5b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9980a056e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9980972a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b0539d9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2afc5cec7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2afc28f81c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2afc28f8a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2afc1248b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2afc5cf9169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2afc5cf8a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2afc5cf8a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b063a5566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b063a4c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b063a4c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b060657dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0606586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b05efa87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acefae3a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acefada7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acefada7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acec6e61c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acec6e6a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aceb036b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2b092ce93630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b097799969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b097799237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0977992529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b092d159a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b092d159dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9980972d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b994ca2cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b994ca35735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9935f36630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9980a3c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9980a3537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9980a35529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abc14600446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abc145aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abc14517a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2afc12751a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2afc12751dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2afc5cfb0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b063a58d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2acefae7169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b09779b8446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b09779626e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b09778cfa18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b99361fca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b99361fcdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9980a5b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abc14517d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abbe05d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abbe05da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abbc9adb630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abc145e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abc145da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abc145da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2afc5cf5a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2afc5cec7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2afc5cec7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2afc28f81c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2afc28f8a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2afc1248b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adc105ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adc105566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adc104c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b133f456446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b133f4006e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b133f36da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b09778cfd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9980a056e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9980972a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9980972d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b994ca2cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b994ca35735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9935f36630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abbc9da1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abbc9da1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abc14600446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2afc5cf9169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adc104c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adbdc57dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adbdc586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adbc5a87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2adc1058d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adc1058637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adc10586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b133f36dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b130b427c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b130b430735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b12f4931630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b133f43769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b133f43037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b133f430529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab0e219d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab0e21476e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab0e20b4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #7: <unknown function> + 0x6f69f (0x2b9980a3c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abc145aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abc14517a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abc14517d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abbe05d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abbe05da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2abbc9adb630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6d512df446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b6d512896e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b6d511f6a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adbc5d4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adbc5d4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adc105ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b12f4bf7a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b12f4bf7dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b133f456446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab0e20b4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab0ae16ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab0ae177735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab097678630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab0e217e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab0e217737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab0e2177529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b5a650b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b5a650b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5a1a87aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5a1a87adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #7: <unknown function> + 0x6f69f (0x2abc145e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b6d511f6d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b6d1d2b0c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b6d1d2b9735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b6d067ba630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b6d512c069f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b6d512b937b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b6d512b9529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adc105566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adc104c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adc104c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adbdc57dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adbdc586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adbc5a87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b133f4006e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b133f36da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b133f36dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b130b427c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b130b430735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b12f4931630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab09793ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab09793edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab0e219d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b5a650d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b5a650836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b5a64ff0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b5a64ff0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b5a310aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b5a310b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b29beeb5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b29bee5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b29bedcca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b6d06a80a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b6d06a80dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6d512df446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2adc1058d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b133f43769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab0e21476e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab0e20b4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab0e20b4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab0ae16ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab0ae177735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab097678630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2b5a1a5b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b5a650ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b5a650b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b5a650b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5a1a87aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5a1a87adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b29bedccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b298ae86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b298ae8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2974390630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b29bee9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b29bee8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b29bee8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b6d512896e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b6d511f6a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b6d511f6d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b6d1d2b0c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b6d1d2b9735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b6d067ba630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b95450f437b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b95450f4529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b94fa8bba78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b94fa8bbdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b36122aa37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b36122aa529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b35c7a71a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b35c7a71dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #7: <unknown function> + 0x6f69f (0x2ab0e217e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b5a650d9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b5a650836e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b5a64ff0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2974656a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2974656dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b29beeb5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #7: <unknown function> + 0x6f69f (0x2b6d512c069f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b954511a446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b95450c46e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9545031a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9545031d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b95110ebc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b95110f4735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b36122d0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b361227a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b36121e7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b36121e7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b35de2a1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b35de2aa735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b4142c7637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b4142c76529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b40f843da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b40f843ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b5a64ff0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b29bee5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b29bedcca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b29bedccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b298ae86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b298ae8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2974390630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af29b49737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af29b497529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af250c5ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af250c5edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b94fa5f5630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b95450fb69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b95450f437b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b95450f4529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b94fa8bba78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b94fa8bbdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #6: <unknown function> + 0x5fb630 (0x2b35c77ab630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b36122b169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b36122aa37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b36122aa529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b35c7a71a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b35c7a71dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4142c9c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b4142c466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b4142bb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b4142bb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b410ec6dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1e9034737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1e90347529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1e45b0ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1e45b0edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #7: <unknown function> + 0x6f69f (0x2b29bee9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af29b4bd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af29b4676e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af29b3d4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af29b3d4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af26748ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af267497735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b954511a446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b95450c46e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9545031a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b61f00d8c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b61f00e1735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b61d95e2630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b62240e869f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b62240e137b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b62240e1529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b61d98a8a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #5: <unknown function> + 0x102a735 (0x2b410ec76735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b40f8177630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b4142c7d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b4142c7637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b4142c76529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b40f843da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b40f843ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1e9036d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1e903176e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1e90284a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1e90284d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1e5c33ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1e5c347735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b19b6c62446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b19b6c0c6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b19b6b79a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af250998630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af29b49e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af29b49737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af29b497529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af250c5ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af250c5edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9545031d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b61d98a8dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b4142c9c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b4142c466e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b4142bb3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1e45848630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1e9034e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1e9034737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1e90347529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1e45b0ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1e45b0edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b19b6b79d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1982c33c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1982c3c735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b196c13d630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b19b6c4369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b19b6c3c37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b19b6c3c529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2af29b4bd446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2af29b4676e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2af29b3d4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1b1586b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1b1586b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1acb032a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1acb032dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acefae6a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acefae6a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aceb0631a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aceb0631dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b4142bb3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b55d643837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b55d6438529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b558bbffa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b558bbffdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #10: <unknown function> + 0x8c1a78 (0x2b196c403a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b196c403dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b19b6c62446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2af29b3d4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1b15891446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1b1583b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1b157a8a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1b157a8d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1ae1862c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1ae186b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acefae90446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acefae3a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acefada7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acefada7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2acec6e61c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acec6e6a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac482c5c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac482c066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac482b73a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b55d645e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b55d64086e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b55d6375a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b55d6375d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b55a242fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b19b6c0c6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b19b6b79a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b19b6b79d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1982c33c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1982c3c735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b196c13d630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8b23aa337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8b23aa3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8ad926aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8ad926adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b1acad6c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1b1587269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1b1586b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1b1586b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1acb032a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1acb032dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #6: <unknown function> + 0x5fb630 (0x2aceb036b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acefae7169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acefae6a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acefae6a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aceb0631a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aceb0631dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>



  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac482b73d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac44ec2dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac44ec36735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac438137630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac482c3d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac482c3637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac482c36529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #5: <unknown function> + 0x102a735 (0x2b55a2438735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b558b939630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b55d643f69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b55d643837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b55d6438529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b558bbffa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b558bbffdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b19b6c4369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8b23ac9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8b23a736e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8b239e0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8b239e0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b8aefa9ac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8aefaa3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b1b15891446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b1b1583b6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b1b157a8a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2acefae90446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2acefae3a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2acefada7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac4383fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac4383fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac482c5c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
<omitting python frames>

CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b55d645e446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b55d64086e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b55d6375a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b0539d8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0539d8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b04ef556a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b04ef556dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b8ad8fa4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8b23aaa69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8b23aa337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8b23aa3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8ad926aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8ad926adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b1b157a8d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2acefada7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac482c066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac482b73a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac482b73d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac44ec2dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac44ec36735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac438137630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b55d6375d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b0539db5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b0539d5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b0539ccca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b0539cccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0505d86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0505d8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b8b23ac9446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b8b23a736e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b8b239e0a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b063a58637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b063a586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b05efd4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b05efd4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b133f43037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b133f430529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b12f4bf7a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b12f4bf7dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #7: <unknown function> + 0x6f69f (0x2ac482c3d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9980a3537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9980a35529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b99361fca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b99361fcdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b04ef290630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b0539d9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b0539d8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0539d8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b04ef556a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b04ef556dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b8b239e0d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b063a5ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b063a5566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b063a4c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b063a4c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b060657dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0606586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b133f456446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b133f4006e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b133f36da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b133f36dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b130b427c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b0943989c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0943992735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b092ce93630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b097799969f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b097799237b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0977992529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b092d159a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9980a5b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9980a056e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9980972a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9980972d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b994ca2cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b994ca35735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b0539db5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b0539d5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b0539ccca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2afc5cf8a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2afc5cf8a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2afc12751a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2afc12751dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2b05efa87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b063a58d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b063a58637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b063a586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b05efd4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b05efd4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
frame #5: <unknown function> + 0x102a735 (0x2b130b430735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b12f4931630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b133f43769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b133f43037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b133f430529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b12f4bf7a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b12f4bf7dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b092d159dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #6: <unknown function> + 0x5fb630 (0x2b9935f36630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9980a3c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9980a3537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9980a35529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b99361fca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b99361fcdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b0539cccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2afc5cfb0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2afc5cf5a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2afc5cec7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2afc5cec7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2afc28f81c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2afc28f8a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b063a5ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b063a5566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b063a4c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b133f456446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b133f4006e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b133f36da18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab0e217737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab0e2177529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab09793ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab09793edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b9980a5b446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b9980a056e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b9980972a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abc145da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abc145da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abbc9da1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abbc9da1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2afc1248b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2afc5cf9169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2afc5cf8a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2afc5cf8a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2afc12751a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2afc12751dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b063a4c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b133f36dd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab0e219d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab0e21476e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab0e20b4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab0e20b4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ab0ae16ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab0ae177735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b9980972d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2abc14600446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2abc145aa6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2abc14517a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2abc14517d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2abbe05d1c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2abbe05da735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2afc5cfb0446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2afc5cf5a6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2afc5cec7a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adc1058637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adc10586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adbc5d4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adbc5d4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #4: <unknown function> + 0x1021c4a (0x2acec6e61c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2acec6e6a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2aceb036b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2acefae7169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2acefae6a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2acefae6a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2aceb0631a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab097678630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab0e217e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab0e217737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab0e2177529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab09793ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab09793edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  
CUDA error: initialization error
frame #4: <unknown function> + 0x1021c4a (0x2b5a310aac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b5a310b3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b5a1a5b4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b5a650ba69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b5a650b337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b5a650b3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b5a1a87aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x5fb630 (0x2abbc9adb630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2abc145e169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2abc145da37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2abc145da529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2abbc9da1a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2abbc9da1dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2afc5cec7d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adc105ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adc105566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adc104c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adc104c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adbdc57dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adbdc586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2aceb0631dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ab0e219d446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ab0e21476e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ab0e20b4a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b5a1a87adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b29bee8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b29bee8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2974656a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2974656dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b6d512b937b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b6d512b9529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b6d06a80a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b6d06a80dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #6: <unknown function> + 0x5fb630 (0x2adbc5a87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2adc1058d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adc1058637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adc10586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adbc5d4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adbc5d4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
  what():  CUDA error: initialization error
frame #4: <unknown function> + 0x1021c4a (0x2b130b427c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b130b430735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b12f4931630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b133f43769f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b133f43037b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b133f430529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b12f4bf7a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ab0e20b4d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b55a242fc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b55a2438735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b558b939630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b55d643f69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b55d643837b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b55d6438529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b558bbffa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b29beeb5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b29bee5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b29bedcca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b29bedccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b298ae86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b298ae8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b6d512df446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b6d512896e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b6d511f6a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b6d511f6d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b6d1d2b0c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b6d1d2b9735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2adc105ac446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2adc105566e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2adc104c3a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b12f4bf7dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x1021c4a (0x2b410ec6dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b410ec76735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b40f8177630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b4142c7d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b4142c7637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b4142c76529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b40f843da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b558bbffdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #6: <unknown function> + 0x5fb630 (0x2b2974390630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b29bee9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b29bee8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b29bee8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2974656a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2974656dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():  CUDA error: initialization error
frame #6: <unknown function> + 0x5fb630 (0x2b6d067ba630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b6d512c069f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b6d512b937b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b6d512b9529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b6d06a80a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b6d06a80dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2adc104c3d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b40f843ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x1021c4a (0x2b994ca2cc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b994ca35735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b9935f36630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b9980a3c69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b9980a3537b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b9980a35529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b99361fca78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b29beeb5446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b29bee5f6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b29bedcca18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2af26748ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2af267497735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2af250998630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2af29b49e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2af29b49737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2af29b497529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2af250c5ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: <unknown function> + 0x1021c4a (0x2b95110ebc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b95110f4735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b94fa5f5630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b95450fb69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b95450f437b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b95450f4529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b94fa8bba78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac482c3637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac482c36529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac4383fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac4383fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b99361fcdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b29bedccd02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2af250c5edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b94fa8bbdc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac482c5c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac482c066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac482b73a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac482b73d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2ac44ec2dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b19b6c3c37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b19b6c3c529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b196c403a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b196c403dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

  what():    what():  CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

frame #4: <unknown function> + 0x1021c4a (0x2b8aefa9ac4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b8aefaa3735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b8ad8fa4630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b8b23aaa69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b8b23aa337b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b8b23aa3529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b8ad926aa78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1ae1862c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1ae186b735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b1acad6c630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b1b1587269f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b1b1586b37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b1b1586b529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b1acb032a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #5: <unknown function> + 0x102a735 (0x2ac44ec36735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac438137630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac482c3d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac482c3637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac482c36529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac4383fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac4383fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b19b6c62446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b19b6c0c6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b19b6b79a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b19b6b79d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2b1982c33c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b8ad926adc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b1acb032dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2ac482c5c446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2ac482c066e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2ac482b73a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1982c3c735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b196c13d630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b19b6c4369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b19b6c3c37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b19b6c3c529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b196c403a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b196c403dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: <unknown function> + 0x1021c4a (0x2afc28f81c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2afc28f8a735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2afc1248b630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2afc5cf9169f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2afc5cf8a37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2afc5cf8a529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2afc12751a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #4: <unknown function> + 0x1021c4a (0x2b060657dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0606586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b05efa87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b063a58d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b063a58637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b063a586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b05efd4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2ac482b73d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
<omitting python frames>
CUDA error: initialization error
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x2b19b6c62446 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x2b19b6c0c6e4 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x2b19b6b79a18 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2afc12751dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b05efd4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #4: <unknown function> + 0x1021c4a (0x2ab0ae16ec4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ab0ae177735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ab097678630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ab0e217e69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ab0e217737b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ab0e2177529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ab09793ea78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #3: c10::cuda::ExchangeDevice(signed char) + 0x92 (0x2b19b6b79d02 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1021c4a (0x2adbdc57dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2adbdc586735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2adbc5a87630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2adc1058d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2adc1058637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2adc10586529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2adbc5d4da78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ab09793edc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x1021c4a (0x2b0505d86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b0505d8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b04ef290630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b0539d9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b0539d8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b0539d8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b04ef556a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2adbc5d4ddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x1021c4a (0x2ac44ec2dc4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2ac44ec36735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2ac438137630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2ac482c3d69f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2ac482c3637b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2ac482c36529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2ac4383fda78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b04ef556dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2ac4383fddc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


frame #4: <unknown function> + 0x1021c4a (0x2b298ae86c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b298ae8f735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b2974390630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b29bee9669f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b29bee8f37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b29bee8f529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b2974656a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b2974656dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>

frame #4: <unknown function> + 0x1021c4a (0x2b1982c33c4a in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0x102a735 (0x2b1982c3c735 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0x5fb630 (0x2b196c13d630 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #7: <unknown function> + 0x6f69f (0x2b19b6c4369f in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x21b (0x2b19b6c3c37b in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #9: c10::TensorImpl::~TensorImpl() + 0x9 (0x2b19b6c3c529 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libc10.so)
frame #10: <unknown function> + 0x8c1a78 (0x2b196c403a78 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
frame #11: THPVariable_subclass_dealloc(_object*) + 0x2c6 (0x2b196c403dc6 in /home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>


[rank23]: Traceback (most recent call last):
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank23]:     data = self._data_queue.get(timeout=timeout)
[rank23]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank23]:     self.not_empty.wait(remaining)
[rank23]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank23]:     gotit = waiter.acquire(True, timeout)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank23]:     _error_if_any_worker_fails()
[rank23]: RuntimeError: DataLoader worker (pid 13339) is killed by signal: Aborted. 

[rank23]: The above exception was the direct cause of the following exception:

[rank23]: Traceback (most recent call last):
[rank23]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank9]: Traceback (most recent call last):
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank9]:     data = self._data_queue.get(timeout=timeout)
[rank9]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank9]:     self.not_empty.wait(remaining)
[rank9]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank9]:     gotit = waiter.acquire(True, timeout)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank9]:     _error_if_any_worker_fails()
[rank9]: RuntimeError: DataLoader worker (pid 12386) is killed by signal: Aborted. 

[rank9]: The above exception was the direct cause of the following exception:

[rank9]: Traceback (most recent call last):
[rank9]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank9]:     main(
[rank23]:     main(
[rank23]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank23]:     trainer.fit(
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank23]:     call._call_and_handle_interrupt(
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank23]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank23]:     return function(*args, **kwargs)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank23]:     self._run(model, ckpt_path=ckpt_path)
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank1]:     data = self._data_queue.get(timeout=timeout)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank1]:     self.not_empty.wait(remaining)
[rank1]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank1]:     gotit = waiter.acquire(True, timeout)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank1]:     _error_if_any_worker_fails()
[rank1]: RuntimeError: DataLoader worker (pid 15066) is killed by signal: Aborted. 

[rank1]: The above exception was the direct cause of the following exception:

[rank1]: Traceback (most recent call last):
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank1]:     main(
[rank9]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank9]:     trainer.fit(
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank9]:     call._call_and_handle_interrupt(
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank9]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank9]:     return function(*args, **kwargs)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank9]:     self._run(model, ckpt_path=ckpt_path)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank23]:     results = self._run_stage()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank23]:     self.fit_loop.run()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank23]:     self.advance()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank23]:     self.epoch_loop.run(self._data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank23]:     self.advance(data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank1]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank1]:     trainer.fit(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank1]:     call._call_and_handle_interrupt(
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank1]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank1]:     return function(*args, **kwargs)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank1]:     self._run(model, ckpt_path=ckpt_path)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank9]:     results = self._run_stage()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank9]:     self.fit_loop.run()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank9]:     self.advance()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank9]:     self.epoch_loop.run(self._data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank9]:     self.advance(data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank23]:     batch, _, __ = next(data_fetcher)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank23]:     batch = super().__next__()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank23]:     batch = next(self.iterator)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank23]:     out = next(self._iterator)
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank23]:     out[i] = next(self.iterators[i])
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank23]:     data = self._next_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank1]:     results = self._run_stage()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank1]:     self.fit_loop.run()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank1]:     self.advance()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank1]:     self.epoch_loop.run(self._data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank1]:     self.advance(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank9]:     batch, _, __ = next(data_fetcher)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank9]:     batch = super().__next__()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank9]:     batch = next(self.iterator)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank9]:     out = next(self._iterator)
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank9]:     out[i] = next(self.iterators[i])
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank9]:     data = self._next_data()
[rank4]: Traceback (most recent call last):
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank4]:     data = self._data_queue.get(timeout=timeout)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank4]:     self.not_empty.wait(remaining)
[rank4]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank4]:     gotit = waiter.acquire(True, timeout)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank4]:     _error_if_any_worker_fails()
[rank4]: RuntimeError: DataLoader worker (pid 19834) is killed by signal: Aborted. 

[rank4]: The above exception was the direct cause of the following exception:

[rank4]: Traceback (most recent call last):
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank4]:     main(
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank23]:     idx, data = self._get_data()
[rank1]:     batch, _, __ = next(data_fetcher)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank1]:     batch = super().__next__()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank1]:     batch = next(self.iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank1]:     out = next(self._iterator)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank1]:     out[i] = next(self.iterators[i])
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank1]:     data = self._next_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank9]:     idx, data = self._get_data()
[rank21]: Traceback (most recent call last):
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank21]:     data = self._data_queue.get(timeout=timeout)
[rank21]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank21]:     self.not_empty.wait(remaining)
[rank21]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank21]:     gotit = waiter.acquire(True, timeout)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank21]:     _error_if_any_worker_fails()
[rank21]: RuntimeError: DataLoader worker (pid 13328) is killed by signal: Aborted. 

[rank21]: The above exception was the direct cause of the following exception:

[rank21]: Traceback (most recent call last):
[rank21]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank1]:     idx, data = self._get_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank9]:     success, data = self._try_get_data()
[rank9]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank9]:     raise RuntimeError(
[rank9]: RuntimeError: DataLoader worker (pid(s) 12369, 12373, 12377, 12386) exited unexpectedly
[rank21]:     main(
[rank21]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank21]:     trainer.fit(
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank21]:     call._call_and_handle_interrupt(
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank21]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank21]:     return function(*args, **kwargs)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank21]:     self._run(model, ckpt_path=ckpt_path)
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank1]:     success, data = self._try_get_data()
[rank1]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank1]:     raise RuntimeError(
[rank1]: RuntimeError: DataLoader worker (pid(s) 15046, 15051, 15055, 15066) exited unexpectedly
[rank11]: Traceback (most recent call last):
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank11]:     data = self._data_queue.get(timeout=timeout)
[rank11]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank11]:     self.not_empty.wait(remaining)
[rank11]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank11]:     gotit = waiter.acquire(True, timeout)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank11]:     _error_if_any_worker_fails()
[rank11]: RuntimeError: DataLoader worker (pid 12376) is killed by signal: Aborted. 

[rank11]: The above exception was the direct cause of the following exception:

[rank11]: Traceback (most recent call last):
[rank11]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank21]:     results = self._run_stage()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank21]:     self.fit_loop.run()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank21]:     self.advance()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank21]:     self.epoch_loop.run(self._data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank21]:     self.advance(data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank2]:     data = self._data_queue.get(timeout=timeout)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank2]:     self.not_empty.wait(remaining)
[rank2]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank2]:     gotit = waiter.acquire(True, timeout)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank2]:     _error_if_any_worker_fails()
[rank2]: RuntimeError: DataLoader worker (pid 15048) is killed by signal: Aborted. 

[rank2]: The above exception was the direct cause of the following exception:

[rank2]: Traceback (most recent call last):
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank2]:     main(
[rank11]:     main(
[rank11]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank11]:     trainer.fit(
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank11]:     call._call_and_handle_interrupt(
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank11]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank11]:     return function(*args, **kwargs)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank11]:     self._run(model, ckpt_path=ckpt_path)
[rank4]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank4]:     trainer.fit(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank4]:     call._call_and_handle_interrupt(
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank4]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank4]:     return function(*args, **kwargs)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank4]:     self._run(model, ckpt_path=ckpt_path)
[rank12]: Traceback (most recent call last):
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank12]:     data = self._data_queue.get(timeout=timeout)
[rank12]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank12]:     self.not_empty.wait(remaining)
[rank12]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank12]:     gotit = waiter.acquire(True, timeout)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank12]:     _error_if_any_worker_fails()
[rank12]: RuntimeError: DataLoader worker (pid 4079) is killed by signal: Aborted. 

[rank12]: The above exception was the direct cause of the following exception:

[rank12]: Traceback (most recent call last):
[rank12]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank21]:     batch, _, __ = next(data_fetcher)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank21]:     batch = super().__next__()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank21]:     batch = next(self.iterator)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank21]:     out = next(self._iterator)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank21]:     out[i] = next(self.iterators[i])
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank21]:     data = self._next_data()
[rank2]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank2]:     trainer.fit(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank2]:     call._call_and_handle_interrupt(
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank2]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank2]:     return function(*args, **kwargs)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank2]:     self._run(model, ckpt_path=ckpt_path)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank11]:     results = self._run_stage()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank11]:     self.fit_loop.run()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank11]:     self.advance()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank11]:     self.epoch_loop.run(self._data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank11]:     self.advance(data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank4]:     results = self._run_stage()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank4]:     self.fit_loop.run()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank4]:     self.advance()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank4]:     self.epoch_loop.run(self._data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank4]:     self.advance(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank12]:     main(
[rank12]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank12]:     trainer.fit(
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank12]:     call._call_and_handle_interrupt(
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank12]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank12]:     return function(*args, **kwargs)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank12]:     self._run(model, ckpt_path=ckpt_path)
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank21]:     idx, data = self._get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank2]:     results = self._run_stage()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank2]:     self.fit_loop.run()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank2]:     self.advance()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank2]:     self.epoch_loop.run(self._data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank2]:     self.advance(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank11]:     batch, _, __ = next(data_fetcher)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank11]:     batch = super().__next__()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank11]:     batch = next(self.iterator)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank11]:     out = next(self._iterator)
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank11]:     out[i] = next(self.iterators[i])
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank11]:     data = self._next_data()
[rank4]:     batch, _, __ = next(data_fetcher)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank4]:     batch = super().__next__()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank4]:     batch = next(self.iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank4]:     out = next(self._iterator)
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank4]:     out[i] = next(self.iterators[i])
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank4]:     data = self._next_data()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank12]:     results = self._run_stage()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank12]:     self.fit_loop.run()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank12]:     self.advance()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank12]:     self.epoch_loop.run(self._data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank12]:     self.advance(data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank23]:     success, data = self._try_get_data()
[rank23]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank23]:     raise RuntimeError(
[rank23]: RuntimeError: DataLoader worker (pid(s) 13327, 13331, 13335, 13339) exited unexpectedly
[rank2]:     batch, _, __ = next(data_fetcher)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank2]:     batch = super().__next__()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank2]:     batch = next(self.iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank2]:     out = next(self._iterator)
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank2]:     out[i] = next(self.iterators[i])
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank2]:     data = self._next_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank11]:     idx, data = self._get_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank4]:     idx, data = self._get_data()
[rank12]:     batch, _, __ = next(data_fetcher)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank12]:     batch = super().__next__()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank12]:     batch = next(self.iterator)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank12]:     out = next(self._iterator)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank12]:     out[i] = next(self.iterators[i])
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank12]:     data = self._next_data()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank21]:     success, data = self._try_get_data()
[rank21]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank21]:     raise RuntimeError(
[rank21]: RuntimeError: DataLoader worker (pid(s) 13328, 13332, 13336, 13341) exited unexpectedly
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank2]:     idx, data = self._get_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank11]:     success, data = self._try_get_data()
[rank11]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank11]:     raise RuntimeError(
[rank11]: RuntimeError: DataLoader worker (pid(s) 12368, 12372, 12376, 12385) exited unexpectedly
[rank5]: Traceback (most recent call last):
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank5]:     data = self._data_queue.get(timeout=timeout)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank5]:     self.not_empty.wait(remaining)
[rank5]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank5]:     gotit = waiter.acquire(True, timeout)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank5]:     _error_if_any_worker_fails()
[rank5]: RuntimeError: DataLoader worker (pid 19839) is killed by signal: Aborted. 

[rank5]: The above exception was the direct cause of the following exception:

[rank5]: Traceback (most recent call last):
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank5]:     main(
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank12]:     idx, data = self._get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank2]:     success, data = self._try_get_data()
[rank2]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank2]:     raise RuntimeError(
[rank2]: RuntimeError: DataLoader worker (pid(s) 15044, 15048, 15053, 15056) exited unexpectedly
[rank5]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank5]:     trainer.fit(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank5]:     call._call_and_handle_interrupt(
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank5]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank5]:     return function(*args, **kwargs)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank5]:     self._run(model, ckpt_path=ckpt_path)
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank12]:     success, data = self._try_get_data()
[rank12]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank12]:     raise RuntimeError(
[rank12]: RuntimeError: DataLoader worker (pid(s) 4055, 4059, 4063, 4079) exited unexpectedly
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank5]:     results = self._run_stage()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank5]:     self.fit_loop.run()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank5]:     self.advance()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank5]:     self.epoch_loop.run(self._data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank5]:     self.advance(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank15]: Traceback (most recent call last):
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank15]:     data = self._data_queue.get(timeout=timeout)
[rank15]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank15]:     self.not_empty.wait(remaining)
[rank15]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank15]:     gotit = waiter.acquire(True, timeout)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank15]:     _error_if_any_worker_fails()
[rank15]: RuntimeError: DataLoader worker (pid 4064) is killed by signal: Aborted. 

[rank15]: The above exception was the direct cause of the following exception:

[rank15]: Traceback (most recent call last):
[rank15]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank5]:     batch, _, __ = next(data_fetcher)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank5]:     batch = super().__next__()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank5]:     batch = next(self.iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank5]:     out = next(self._iterator)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank5]:     out[i] = next(self.iterators[i])
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank5]:     data = self._next_data()
[rank15]:     main(
[rank15]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank15]:     trainer.fit(
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank15]:     call._call_and_handle_interrupt(
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank15]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank15]:     return function(*args, **kwargs)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank15]:     self._run(model, ckpt_path=ckpt_path)
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank5]:     idx, data = self._get_data()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank15]:     results = self._run_stage()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank15]:     self.fit_loop.run()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank15]:     self.advance()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank15]:     self.epoch_loop.run(self._data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank15]:     self.advance(data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank4]:     success, data = self._try_get_data()
[rank4]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank4]:     raise RuntimeError(
[rank4]: RuntimeError: DataLoader worker (pid(s) 19820, 19825, 19829, 19834) exited unexpectedly
[rank15]:     batch, _, __ = next(data_fetcher)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank15]:     batch = super().__next__()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank15]:     batch = next(self.iterator)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank15]:     out = next(self._iterator)
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank15]:     out[i] = next(self.iterators[i])
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank15]:     data = self._next_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank5]:     success, data = self._try_get_data()
[rank5]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank5]:     raise RuntimeError(
[rank5]: RuntimeError: DataLoader worker (pid(s) 19821, 19826, 19830, 19839) exited unexpectedly
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank15]:     idx, data = self._get_data()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank15]:     success, data = self._try_get_data()
[rank15]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank15]:     raise RuntimeError(
[rank15]: RuntimeError: DataLoader worker (pid(s) 4052, 4056, 4060, 4064) exited unexpectedly
[rank20]: Traceback (most recent call last):
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank20]:     data = self._data_queue.get(timeout=timeout)
[rank20]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank20]:     self.not_empty.wait(remaining)
[rank20]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank20]:     gotit = waiter.acquire(True, timeout)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank20]:     _error_if_any_worker_fails()
[rank20]: RuntimeError: DataLoader worker (pid 13330) is killed by signal: Aborted. 

[rank20]: The above exception was the direct cause of the following exception:

[rank20]: Traceback (most recent call last):
[rank20]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank20]:     main(
[rank20]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank20]:     trainer.fit(
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank20]:     call._call_and_handle_interrupt(
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank20]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank20]:     return function(*args, **kwargs)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank20]:     self._run(model, ckpt_path=ckpt_path)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank20]:     results = self._run_stage()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank20]:     self.fit_loop.run()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank20]:     self.advance()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank20]:     self.epoch_loop.run(self._data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank20]:     self.advance(data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank20]:     batch, _, __ = next(data_fetcher)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank20]:     batch = super().__next__()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank20]:     batch = next(self.iterator)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank20]:     out = next(self._iterator)
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank20]:     out[i] = next(self.iterators[i])
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank20]:     data = self._next_data()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank20]:     idx, data = self._get_data()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank20]:     success, data = self._try_get_data()
[rank20]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank20]:     raise RuntimeError(
[rank20]: RuntimeError: DataLoader worker (pid(s) 13330, 13333, 13337, 13343) exited unexpectedly
[rank7]: Traceback (most recent call last):
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank7]:     data = self._data_queue.get(timeout=timeout)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank7]:     self.not_empty.wait(remaining)
[rank7]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank7]:     gotit = waiter.acquire(True, timeout)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 70, in handler
[rank7]:     def handler(signum, frame):
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank7]:     _error_if_any_worker_fails()
[rank7]: RuntimeError: DataLoader worker (pid 19819) is killed by signal: Aborted. 

[rank7]: The above exception was the direct cause of the following exception:

[rank7]: Traceback (most recent call last):
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank7]:     main(
[rank7]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank7]:     trainer.fit(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank7]:     call._call_and_handle_interrupt(
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank7]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank7]:     return function(*args, **kwargs)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank7]:     self._run(model, ckpt_path=ckpt_path)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank7]:     results = self._run_stage()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank7]:     self.fit_loop.run()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank7]:     self.advance()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank7]:     self.epoch_loop.run(self._data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank7]:     self.advance(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank7]:     batch, _, __ = next(data_fetcher)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank7]:     batch = super().__next__()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank7]:     batch = next(self.iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank7]:     out = next(self._iterator)
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank7]:     out[i] = next(self.iterators[i])
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank7]:     data = self._next_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank7]:     idx, data = self._get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank7]:     success, data = self._try_get_data()
[rank7]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank7]:     raise RuntimeError(
[rank7]: RuntimeError: DataLoader worker (pid(s) 19819, 19823, 19827, 19832) exited unexpectedly
[rank22]: Traceback (most recent call last):
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank22]:     data = self._data_queue.get(timeout=timeout)
[rank22]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank22]:     self.not_empty.wait(remaining)
[rank22]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank22]:     gotit = waiter.acquire(True, timeout)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank22]:     _error_if_any_worker_fails()
[rank22]: RuntimeError: DataLoader worker (pid 13349) is killed by signal: Aborted. 

[rank22]: The above exception was the direct cause of the following exception:

[rank22]: Traceback (most recent call last):
[rank22]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank22]:     main(
[rank22]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank22]:     trainer.fit(
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank22]:     call._call_and_handle_interrupt(
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank22]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank22]:     return function(*args, **kwargs)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank22]:     self._run(model, ckpt_path=ckpt_path)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank22]:     results = self._run_stage()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank22]:     self.fit_loop.run()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank22]:     self.advance()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank22]:     self.epoch_loop.run(self._data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank22]:     self.advance(data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank22]:     batch, _, __ = next(data_fetcher)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank22]:     batch = super().__next__()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank22]:     batch = next(self.iterator)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank22]:     out = next(self._iterator)
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank22]:     out[i] = next(self.iterators[i])
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank22]:     data = self._next_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank22]:     idx, data = self._get_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank22]:     success, data = self._try_get_data()
[rank22]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank22]:     raise RuntimeError(
[rank22]: RuntimeError: DataLoader worker (pid(s) 13329, 13334, 13338, 13349) exited unexpectedly
[rank8]: Traceback (most recent call last):
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank8]:     data = self._data_queue.get(timeout=timeout)
[rank8]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank8]:     self.not_empty.wait(remaining)
[rank8]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank8]:     gotit = waiter.acquire(True, timeout)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank8]:     _error_if_any_worker_fails()
[rank8]: RuntimeError: DataLoader worker (pid 12367) is killed by signal: Aborted. 

[rank8]: The above exception was the direct cause of the following exception:

[rank8]: Traceback (most recent call last):
[rank8]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank8]:     main(
[rank8]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank8]:     trainer.fit(
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank8]:     call._call_and_handle_interrupt(
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank8]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank8]:     return function(*args, **kwargs)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank8]:     self._run(model, ckpt_path=ckpt_path)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank8]:     results = self._run_stage()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank8]:     self.fit_loop.run()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank8]:     self.advance()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank8]:     self.epoch_loop.run(self._data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank8]:     self.advance(data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank8]:     batch, _, __ = next(data_fetcher)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank8]:     batch = super().__next__()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank8]:     batch = next(self.iterator)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank8]:     out = next(self._iterator)
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank8]:     out[i] = next(self.iterators[i])
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank8]:     data = self._next_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank8]:     idx, data = self._get_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank8]:     success, data = self._try_get_data()
[rank8]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank8]:     raise RuntimeError(
[rank8]: RuntimeError: DataLoader worker (pid(s) 12367, 12371, 12375, 12380) exited unexpectedly
[rank6]: Traceback (most recent call last):
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank6]:     data = self._data_queue.get(timeout=timeout)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank6]:     self.not_empty.wait(remaining)
[rank6]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank6]:     gotit = waiter.acquire(True, timeout)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank6]:     _error_if_any_worker_fails()
[rank6]: RuntimeError: DataLoader worker (pid 19831) is killed by signal: Aborted. 

[rank6]: The above exception was the direct cause of the following exception:

[rank6]: Traceback (most recent call last):
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank6]:     main(
[rank6]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank6]:     trainer.fit(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank6]:     call._call_and_handle_interrupt(
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank6]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank6]:     return function(*args, **kwargs)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank6]:     self._run(model, ckpt_path=ckpt_path)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank6]:     results = self._run_stage()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank6]:     self.fit_loop.run()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank6]:     self.advance()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank6]:     self.epoch_loop.run(self._data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank6]:     self.advance(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank6]:     batch, _, __ = next(data_fetcher)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank6]:     batch = super().__next__()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank6]:     batch = next(self.iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank6]:     out = next(self._iterator)
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank6]:     out[i] = next(self.iterators[i])
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank6]:     data = self._next_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank6]:     idx, data = self._get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank6]:     success, data = self._try_get_data()
[rank6]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank6]:     raise RuntimeError(
[rank6]: RuntimeError: DataLoader worker (pid(s) 19822, 19824, 19828, 19831) exited unexpectedly
[rank0]: Traceback (most recent call last):
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank0]:     data = self._data_queue.get(timeout=timeout)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank0]:     self.not_empty.wait(remaining)
[rank0]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank0]:     gotit = waiter.acquire(True, timeout)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank0]:     _error_if_any_worker_fails()
[rank0]: RuntimeError: DataLoader worker (pid 15052) is killed by signal: Aborted. 

[rank0]: The above exception was the direct cause of the following exception:

[rank0]: Traceback (most recent call last):
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank0]:     main(
[rank0]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank0]:     trainer.fit(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank0]:     self._run(model, ckpt_path=ckpt_path)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank0]:     results = self._run_stage()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank0]:     self.fit_loop.run()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank0]:     self.advance()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank0]:     self.epoch_loop.run(self._data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank0]:     self.advance(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank0]:     batch, _, __ = next(data_fetcher)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank0]:     batch = super().__next__()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank0]:     batch = next(self.iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank0]:     out = next(self._iterator)
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank0]:     out[i] = next(self.iterators[i])
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank0]:     idx, data = self._get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank0]:     success, data = self._try_get_data()
[rank0]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank0]:     raise RuntimeError(
[rank0]: RuntimeError: DataLoader worker (pid(s) 15045, 15049, 15052) exited unexpectedly
[rank13]: Traceback (most recent call last):
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank13]:     data = self._data_queue.get(timeout=timeout)
[rank13]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank13]:     self.not_empty.wait(remaining)
[rank13]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank13]:     gotit = waiter.acquire(True, timeout)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank13]:     _error_if_any_worker_fails()
[rank13]: RuntimeError: DataLoader worker (pid 4067) is killed by signal: Aborted. 

[rank13]: The above exception was the direct cause of the following exception:

[rank13]: Traceback (most recent call last):
[rank13]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank13]:     main(
[rank13]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank13]:     trainer.fit(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank13]:     call._call_and_handle_interrupt(
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank13]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank13]:     return function(*args, **kwargs)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank13]:     self._run(model, ckpt_path=ckpt_path)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank13]:     results = self._run_stage()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank13]:     self.fit_loop.run()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank13]:     self.advance()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank13]:     self.epoch_loop.run(self._data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank13]:     self.advance(data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank13]:     batch, _, __ = next(data_fetcher)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank13]:     batch = super().__next__()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank13]:     batch = next(self.iterator)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank13]:     out = next(self._iterator)
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank13]:     out[i] = next(self.iterators[i])
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank13]:     data = self._next_data()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank13]:     idx, data = self._get_data()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank13]:     success, data = self._try_get_data()
[rank13]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank13]:     raise RuntimeError(
[rank13]: RuntimeError: DataLoader worker (pid(s) 4054, 4057, 4061, 4067) exited unexpectedly
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank3]:     data = self._data_queue.get(timeout=timeout)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank3]:     self.not_empty.wait(remaining)
[rank3]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank3]:     gotit = waiter.acquire(True, timeout)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank3]:     _error_if_any_worker_fails()
[rank3]: RuntimeError: DataLoader worker (pid 15059) is killed by signal: Aborted. 

[rank3]: The above exception was the direct cause of the following exception:

[rank3]: Traceback (most recent call last):
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank3]:     main(
[rank14]: Traceback (most recent call last):
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank14]:     data = self._data_queue.get(timeout=timeout)
[rank14]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank14]:     self.not_empty.wait(remaining)
[rank14]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank14]:     gotit = waiter.acquire(True, timeout)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank14]:     _error_if_any_worker_fails()
[rank14]: RuntimeError: DataLoader worker (pid 4070) is killed by signal: Aborted. 

[rank14]: The above exception was the direct cause of the following exception:

[rank14]: Traceback (most recent call last):
[rank14]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank3]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank3]:     trainer.fit(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank3]:     call._call_and_handle_interrupt(
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank3]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank3]:     return function(*args, **kwargs)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank3]:     self._run(model, ckpt_path=ckpt_path)
[rank14]:     main(
[rank14]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank14]:     trainer.fit(
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank14]:     call._call_and_handle_interrupt(
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank14]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank14]:     return function(*args, **kwargs)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank14]:     self._run(model, ckpt_path=ckpt_path)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank3]:     results = self._run_stage()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank3]:     self.fit_loop.run()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank3]:     self.advance()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank3]:     self.epoch_loop.run(self._data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank3]:     self.advance(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank3]:     batch, _, __ = next(data_fetcher)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank3]:     batch = super().__next__()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank3]:     batch = next(self.iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank3]:     out = next(self._iterator)
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank3]:     out[i] = next(self.iterators[i])
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank3]:     data = self._next_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank3]:     idx, data = self._get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank3]:     success, data = self._try_get_data()
[rank3]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank3]:     raise RuntimeError(
[rank3]: RuntimeError: DataLoader worker (pid(s) 15047, 15050, 15054, 15059) exited unexpectedly
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank14]:     results = self._run_stage()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank14]:     self.fit_loop.run()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank14]:     self.advance()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank14]:     self.epoch_loop.run(self._data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank14]:     self.advance(data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank14]:     batch, _, __ = next(data_fetcher)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank14]:     batch = super().__next__()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank14]:     batch = next(self.iterator)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank14]:     out = next(self._iterator)
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank14]:     out[i] = next(self.iterators[i])
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank14]:     data = self._next_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank14]:     idx, data = self._get_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank14]:     success, data = self._try_get_data()
[rank14]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank14]:     raise RuntimeError(
[rank14]: RuntimeError: DataLoader worker (pid(s) 4053, 4058, 4062, 4070) exited unexpectedly
[rank10]: Traceback (most recent call last):
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank10]:     data = self._data_queue.get(timeout=timeout)
[rank10]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank10]:     self.not_empty.wait(remaining)
[rank10]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank10]:     gotit = waiter.acquire(True, timeout)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank10]:     _error_if_any_worker_fails()
[rank10]: RuntimeError: DataLoader worker (pid 12374) is killed by signal: Aborted. 

[rank10]: The above exception was the direct cause of the following exception:

[rank10]: Traceback (most recent call last):
[rank10]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank10]:     main(
[rank10]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank10]:     trainer.fit(
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank10]:     call._call_and_handle_interrupt(
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank10]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank10]:     return function(*args, **kwargs)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank10]:     self._run(model, ckpt_path=ckpt_path)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank10]:     results = self._run_stage()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank10]:     self.fit_loop.run()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank10]:     self.advance()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank10]:     self.epoch_loop.run(self._data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank10]:     self.advance(data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank10]:     batch, _, __ = next(data_fetcher)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank10]:     batch = super().__next__()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank10]:     batch = next(self.iterator)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank10]:     out = next(self._iterator)
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank10]:     out[i] = next(self.iterators[i])
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank10]:     data = self._next_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank10]:     idx, data = self._get_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank10]:     success, data = self._try_get_data()
[rank10]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank10]:     raise RuntimeError(
[rank10]: RuntimeError: DataLoader worker (pid(s) 12366, 12370, 12374, 12378) exited unexpectedly
[rank16]: Traceback (most recent call last):
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank16]:     data = self._data_queue.get(timeout=timeout)
[rank16]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank16]:     self.not_empty.wait(remaining)
[rank16]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank16]:     gotit = waiter.acquire(True, timeout)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank16]:     _error_if_any_worker_fails()
[rank16]: RuntimeError: DataLoader worker (pid 5565) is killed by signal: Aborted. 

[rank16]: The above exception was the direct cause of the following exception:

[rank16]: Traceback (most recent call last):
[rank16]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank16]:     main(
[rank16]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank16]:     trainer.fit(
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank16]:     call._call_and_handle_interrupt(
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank16]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank16]:     return function(*args, **kwargs)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank16]:     self._run(model, ckpt_path=ckpt_path)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank16]:     results = self._run_stage()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank16]:     self.fit_loop.run()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank16]:     self.advance()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank16]:     self.epoch_loop.run(self._data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank16]:     self.advance(data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank16]:     batch, _, __ = next(data_fetcher)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank16]:     batch = super().__next__()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank16]:     batch = next(self.iterator)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank16]:     out = next(self._iterator)
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank16]:     out[i] = next(self.iterators[i])
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank16]:     data = self._next_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank16]:     idx, data = self._get_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank16]:     success, data = self._try_get_data()
[rank16]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank16]:     raise RuntimeError(
[rank16]: RuntimeError: DataLoader worker (pid(s) 5554, 5557, 5561, 5565) exited unexpectedly
[rank18]: Traceback (most recent call last):
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank18]:     data = self._data_queue.get(timeout=timeout)
[rank18]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank18]:     self.not_empty.wait(remaining)
[rank18]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank18]:     gotit = waiter.acquire(True, timeout)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank18]:     _error_if_any_worker_fails()
[rank18]: RuntimeError: DataLoader worker (pid 5552) is killed by signal: Aborted. 

[rank18]: The above exception was the direct cause of the following exception:

[rank18]: Traceback (most recent call last):
[rank18]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank18]:     main(
[rank18]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank18]:     trainer.fit(
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank18]:     call._call_and_handle_interrupt(
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank18]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank18]:     return function(*args, **kwargs)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank18]:     self._run(model, ckpt_path=ckpt_path)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank18]:     results = self._run_stage()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank18]:     self.fit_loop.run()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank18]:     self.advance()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank18]:     self.epoch_loop.run(self._data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank18]:     self.advance(data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank18]:     batch, _, __ = next(data_fetcher)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank18]:     batch = super().__next__()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank18]:     batch = next(self.iterator)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank18]:     out = next(self._iterator)
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank18]:     out[i] = next(self.iterators[i])
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank18]:     data = self._next_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank18]:     idx, data = self._get_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank18]:     success, data = self._try_get_data()
[rank18]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank18]:     raise RuntimeError(
[rank18]: RuntimeError: DataLoader worker (pid(s) 5552, 5556, 5560, 5564) exited unexpectedly
[rank19]: Traceback (most recent call last):
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank19]:     data = self._data_queue.get(timeout=timeout)
[rank19]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank19]:     self.not_empty.wait(remaining)
[rank19]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank19]:     gotit = waiter.acquire(True, timeout)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank19]:     _error_if_any_worker_fails()
[rank19]: RuntimeError: DataLoader worker (pid 5569) is killed by signal: Aborted. 

[rank19]: The above exception was the direct cause of the following exception:

[rank19]: Traceback (most recent call last):
[rank19]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank19]:     main(
[rank19]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank19]:     trainer.fit(
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank19]:     call._call_and_handle_interrupt(
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank19]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank19]:     return function(*args, **kwargs)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank19]:     self._run(model, ckpt_path=ckpt_path)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank19]:     results = self._run_stage()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank19]:     self.fit_loop.run()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank19]:     self.advance()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank19]:     self.epoch_loop.run(self._data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank19]:     self.advance(data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank19]:     batch, _, __ = next(data_fetcher)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank19]:     batch = super().__next__()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank19]:     batch = next(self.iterator)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank19]:     out = next(self._iterator)
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank19]:     out[i] = next(self.iterators[i])
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank19]:     data = self._next_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank19]:     idx, data = self._get_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank19]:     success, data = self._try_get_data()
[rank19]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank19]:     raise RuntimeError(
[rank19]: RuntimeError: DataLoader worker (pid(s) 5555, 5558, 5562, 5569) exited unexpectedly
[rank17]: Traceback (most recent call last):
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
[rank17]:     data = self._data_queue.get(timeout=timeout)
[rank17]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/queue.py", line 180, in get
[rank17]:     self.not_empty.wait(remaining)
[rank17]:   File "/opt/apps/intel19/python3/3.9.2/lib/python3.9/threading.py", line 316, in wait
[rank17]:     gotit = waiter.acquire(True, timeout)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
[rank17]:     _error_if_any_worker_fails()
[rank17]: RuntimeError: DataLoader worker (pid 5563) is killed by signal: Aborted. 

[rank17]: The above exception was the direct cause of the following exception:

[rank17]: Traceback (most recent call last):
[rank17]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 101, in <module>
[rank17]:     main(
[rank17]:   File "/work2/10214/yu_yao/frontera/deepfaker/src/Demo_6.py", line 67, in main
[rank17]:     trainer.fit(
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 539, in fit
[rank17]:     call._call_and_handle_interrupt(
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py", line 46, in _call_and_handle_interrupt
[rank17]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py", line 105, in launch
[rank17]:     return function(*args, **kwargs)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 575, in _fit_impl
[rank17]:     self._run(model, ckpt_path=ckpt_path)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
[rank17]:     results = self._run_stage()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py", line 1026, in _run_stage
[rank17]:     self.fit_loop.run()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 216, in run
[rank17]:     self.advance()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py", line 455, in advance
[rank17]:     self.epoch_loop.run(self._data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 150, in run
[rank17]:     self.advance(data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py", line 282, in advance
[rank17]:     batch, _, __ = next(data_fetcher)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 134, in __next__
[rank17]:     batch = super().__next__()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/loops/fetchers.py", line 61, in __next__
[rank17]:     batch = next(self.iterator)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 341, in __next__
[rank17]:     out = next(self._iterator)
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/lightning/pytorch/utilities/combined_loader.py", line 78, in __next__
[rank17]:     out[i] = next(self.iterators[i])
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
[rank17]:     data = self._next_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
[rank17]:     idx, data = self._get_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1402, in _get_data
[rank17]:     success, data = self._try_get_data()
[rank17]:   File "/home1/10214/yu_yao/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
[rank17]:     raise RuntimeError(
[rank17]: RuntimeError: DataLoader worker (pid(s) 5553, 5559, 5563, 5576) exited unexpectedly
srun: error: c198-112: tasks 20-23: Exited with exit code 1
srun: error: c198-011: tasks 8-11: Exited with exit code 1
srun: error: c196-062: tasks 0-3: Exited with exit code 1
srun: error: c197-112: tasks 4-7: Exited with exit code 1
srun: error: c198-111: tasks 16-19: Exited with exit code 1
srun: error: c198-102: tasks 12-15: Exited with exit code 1
